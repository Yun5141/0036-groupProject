{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- import packages -----------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from os import chdir\n",
    "\n",
    "# !pip install sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, precision_recall_curve\n",
    "\n",
    "import io\n",
    "\n",
    "# !pip install geopy\n",
    "from geopy.distance import geodesic \n",
    "from geopy.distance import great_circle \n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# ------------------- import data -------------------------\n",
    "url=\"https://raw.githubusercontent.com/Yun5141/comp0036/master/elp_up-to-date_data.csv\"\n",
    "training_data=pd.read_csv(url)\n",
    "url = \"https://raw.githubusercontent.com/Yun5141/comp0036/master/stadiums-with-GPS-coordinates.csv\"\n",
    "geometricData = pd.read_csv(url)\n",
    "\n",
    "# ------------------ helper functions -------------------\n",
    "# ********************************************\n",
    "# to remove data that contains None, NaN, infinite or overflowed\n",
    "def removeInvalidData(data):\n",
    "\n",
    "    # remove data which contains None\n",
    "    data.dropna(axis=0, how='any',inplace=True)\n",
    "\n",
    "    # remove data which contains NaN, infinite or overflowed number \n",
    "    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    data = data[indices_to_keep]\n",
    "\n",
    "    return data\n",
    "\n",
    "# !!! 【report中: 第一步先检查有无空值】\n",
    "assert training_data.shape[0] == removeInvalidData(training_data).shape[0]\n",
    "#result: there is no empty value at the initial stage \n",
    "\n",
    "# ********************************************\n",
    "# unify the different date formats and convert the type from str to timestamp   [done]\n",
    "def unifyDate(data):\n",
    "\n",
    "    if not isinstance(data.Date[0],str):\n",
    "        return\n",
    "\n",
    "    newDate = []\n",
    "    for _, matchInfo in data.iterrows():\n",
    "        if len(matchInfo.Date) == 8 :\n",
    "            newDate.append( pd.to_datetime(matchInfo.Date, format=\"%d/%m/%y\" ))\n",
    "        elif len(matchInfo.Date) == 9 :\n",
    "            newDate.append( pd.to_datetime(matchInfo.Date, format=\"%d %b %y\" ))\n",
    "        elif len(matchInfo.Date) == 10 :\n",
    "            newDate.append(  pd.to_datetime(matchInfo.Date, format=\"%d/%m/%Y\" ))\n",
    "    \n",
    "    data['Date'] = pd.Series(newDate).values\n",
    "\n",
    "#unifyDate(training_data)\n",
    "\n",
    "# ------------------ Inital Data Exploration -------------------  \n",
    "# ********************************************\n",
    "# to see the number of matches each year / season\n",
    "def separateData(data):\n",
    "    dataframe_collection = {}\n",
    "\n",
    "    for year in range(2008, 2020):\n",
    "        dataframe_collection[year] = data[(data.Date > dt.datetime(year,8,1,0,0) ) & (data.Date < dt.datetime(year+1, 6, 1,0,0))]\n",
    "\n",
    "    return dataframe_collection\n",
    "\n",
    "'''\n",
    "data = separateData(training_data)\n",
    "for key in data.keys():\n",
    "    print(\"\\n\" +\"=\"*40)\n",
    "    print(key)\n",
    "    print(\"-\"*40)\n",
    "    print(data[key])\n",
    "'''\n",
    "#result: 380 rows * 11 dataframes + 170 rows * 1 dataframes = 4350 rows\n",
    "\n",
    "# ********************************************\n",
    "# !!! 【在数据正式处理前后各用一次这个函数，即两次的data exploration section】\n",
    "def checkAverageWinRate(data, resultWinner):\n",
    "\n",
    "    if resultWinner not in ['H', 'A', 'D']:\n",
    "        raise Exception('The second argument should only take values within [“H”,“A”,“D”]')\n",
    "    \n",
    "    n_wins = len(data[data.FTR == resultWinner])\n",
    "\n",
    "    return n_wins / data.shape[0]\n",
    "\n",
    "#prediction = checkAverageWinRate(training_data, 'H')\n",
    "\n",
    "#results of raw data (ie, when nothing applied to the training data): \n",
    "#total number of matches = 4350\n",
    "#home team = 0.4606896551724138 ~ 0.461; \n",
    "#away team = 0.2910344827586207 ~ 0.291;\n",
    "#draw = 0.2482758620689655 ～ 0.248\n",
    "\n",
    "# ------------------- Feature Construction ------------------——————————\n",
    "#*******************************\n",
    "# get the distance needed to travel for the away team   [done] \n",
    "def getDistance(data, geometricData):\n",
    "  array = []\n",
    "  for x in data.iterrows():\n",
    "   \n",
    "    home_lat = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Latitude\n",
    "    home_long = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Longitude\n",
    "    home_location = (np.float32(home_lat), np.float32(home_long))\n",
    "    \n",
    "    away_lat = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Latitude\n",
    "   \n",
    "    away_long = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Longitude\n",
    "    away_location = (np.float32(away_lat), np.float32(away_long))\n",
    "    array.append(np.float32(geodesic(home_location, away_location).km))\n",
    "  \n",
    "  \n",
    "  DIS = pd.Series(array)\n",
    "  data.loc[:,'DIS'] = DIS\n",
    "\n",
    "  return data\n",
    "\n",
    "#getDistance(training_data, geometricData) \n",
    "#print(training_data)\n",
    "\n",
    "#*******************************\n",
    "# get match week    [done]\n",
    "def getMW(data, startYear):  \n",
    "    MW = []\n",
    "    Flag = 0\n",
    "    year = startYear\n",
    "\n",
    "    for _, matchInfo in data.iterrows():\n",
    "        checkYear = (matchInfo.Date > dt.datetime(year,8,1,0,0)) & (matchInfo.Date < dt.datetime(year+1, 6, 1,0,0)) \n",
    "        \n",
    "        if not checkYear:\n",
    "            year += 1\n",
    "            Flag = 0\n",
    "    \n",
    "        if (Flag == 0):\n",
    "            firstDate = matchInfo.Date\n",
    "            Flag = 1\n",
    "\n",
    "        week = (matchInfo.Date - firstDate).days // 7 +1\n",
    "        \n",
    "        MW.append(week) \n",
    "\n",
    "    data.loc[:,'MW'] = pd.Series(MW).values\n",
    "\n",
    "    return data\n",
    "\n",
    "'''\n",
    "使用方法1: 赛季分开成12张分表，则\n",
    "    unifyDateformat(data)\n",
    "    separate(data)\n",
    "然后\n",
    "for key in data.keys():\n",
    "    print(\"\\n\" +\"=\"*40)\n",
    "    print(key)\n",
    "    print(\"-\"*40)\n",
    "    #print(data[key])\n",
    "    print(getMW(data[key], key))\n",
    "\n",
    "使用方法2: 不分赛季，使用完整的表，则\n",
    "    unifyDateFormat(data)\n",
    "然后\n",
    "print(getMW(data, 2008))\n",
    "'''\n",
    "\n",
    "#*******************************\n",
    "# calculate the delta time from last match for home team and away team  [done]\n",
    "def getDeltaTime(data):\n",
    "    \n",
    "    teams = {}\n",
    "\n",
    "    HDT = []\n",
    "    ADT = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if (i % 380 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []    # to store last match date\n",
    "\n",
    "        currentDate = data.iloc[i].Date\n",
    "\n",
    "        try:\n",
    "            homeLastMatchDate = teams[data.iloc[i].HomeTeam].pop()\n",
    "            awayLastMatchDate = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            homeLastMatchDate = currentDate\n",
    "            awayLastMatchDate = currentDate\n",
    "\n",
    "        hdt = currentDate - homeLastMatchDate\n",
    "        adt = currentDate - awayLastMatchDate\n",
    "\n",
    "        HDT.append(hdt.days)\n",
    "        ADT.append(adt.days)\n",
    "\n",
    "        teams[data.iloc[i].HomeTeam].append(currentDate)\n",
    "        teams[data.iloc[i].AwayTeam].append(currentDate)\n",
    "\n",
    "    data.loc[:,'HDT'] = HDT\n",
    "    data.loc[:,'ADT'] = ADT\n",
    "\n",
    "    return data\n",
    "\n",
    "#unifyDateFormat(training_data)\n",
    "#getMW(training_data,2008)\n",
    "#getDeltaTime(training_data)\n",
    "#training_data.loc[377:400,[\"Date\",\"HomeTeam\",\"AwayTeam\",\"MW\",\"HDT\",\"ADT\"]]\n",
    "\n",
    "#*****************************\n",
    "# calculate the cumulative goal difference (before this match) scored by home team and away team    [done]\n",
    "def getCumulativeGoalsDiff(data):\n",
    "    teams = {}\n",
    "    HCGD = [] \n",
    "    ACGD = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if (i % 380 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        FTHG = data.iloc[i]['FTHG']\n",
    "        FTAG = data.iloc[i]['FTAG']\n",
    "\n",
    "        try:\n",
    "            cgd_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            cgd_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            cgd_h = 0\n",
    "            cgd_a = 0\n",
    "\n",
    "        HCGD.append(cgd_h)\n",
    "        ACGD.append(cgd_a)\n",
    "        cgd_h = cgd_h + FTHG - FTAG\n",
    "        teams[data.iloc[i].HomeTeam].append(cgd_h)\n",
    "        cgd_a = cgd_a + FTAG - FTHG\n",
    "        teams[data.iloc[i].AwayTeam].append(cgd_a)\n",
    "\n",
    "    data.loc[:,'HCGD'] = HCGD\n",
    "    data.loc[:,'ACGD'] = ACGD\n",
    "    return data\n",
    "\n",
    "#getCumulativeGoalsDiff(training_data)\n",
    "#training_data\n",
    "\n",
    "#****************************\n",
    "# get average goal difference per week\n",
    "def getAverageGD(data):\n",
    "\n",
    "    data.eval('HAGD = HCGD / MW', inplace=True)\n",
    "    data.eval('AAGD = ACGD / MW', inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# !!!【必须有了CGD与MW之后再写这一个；在第二次explore画图时舍弃CGD，AGD其中一个】\n",
    "# unifyDateFormat(training_data)\n",
    "# getMW(training_data,2008)\n",
    "# getCumulativeGoalsDiff(training_data)\n",
    "# getAverageGD(training_data)\n",
    "\n",
    "#****************************\n",
    "# !!!【 写report时在代码块外提一句: 因为在最开始用separateData()已发现，每年比赛数都是固定的380场，所以循环里可直接用i%380==0来初始化】\n",
    "# 统计每支队伍最近三场比赛的表现    [done]\n",
    "def getPerformanceOfLast3Matches(data):\n",
    "    HM1 = []    # result of the last match of home team\n",
    "    AM1 = []    # result of the last match of away team\n",
    "\n",
    "    HM2 = []    # result of the 2nd last match of home team\n",
    "    AM2 = []\n",
    "\n",
    "    HM3 = []    # result of the 3rd last match of home team\n",
    "    AM3 = []\n",
    "\n",
    "    teams = {}\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if (i % 380 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = deque([None, None, None])  #[3rd, 2nd, latest data]\n",
    "\n",
    "        HM3.append(teams[data.iloc[i].HomeTeam].popleft())\n",
    "        AM3.append(teams[data.iloc[i].AwayTeam].popleft())\n",
    "        HM2.append(teams[data.iloc[i].HomeTeam][0])\n",
    "        AM2.append(teams[data.iloc[i].AwayTeam][0])\n",
    "        HM1.append(teams[data.iloc[i].HomeTeam][1])\n",
    "        AM1.append(teams[data.iloc[i].AwayTeam][1])\n",
    "\n",
    "        if data.iloc[i].FTR == 'H':\n",
    "            # 主场 赢，则主场记为赢，客场记为输\n",
    "            teams[data.iloc[i].HomeTeam].append('W')\n",
    "            teams[data.iloc[i].AwayTeam].append('L')\n",
    "        elif data.iloc[i].FTR == 'A':\n",
    "            # 客场 赢，则主场记为输，客场记为赢\n",
    "            teams[data.iloc[i].AwayTeam].append('W')\n",
    "            teams[data.iloc[i].HomeTeam].append('L')\n",
    "        else:\n",
    "            # 平局\n",
    "            teams[data.iloc[i].AwayTeam].append('D')\n",
    "            teams[data.iloc[i].HomeTeam].append('D')\n",
    "\n",
    "    data.loc[:,'HM1'] = HM1\n",
    "    data.loc[:,'AM1'] = AM1\n",
    "    data.loc[:,'HM2'] = HM2\n",
    "    data.loc[:,'AM2'] = AM2\n",
    "    data.loc[:,'HM3'] = HM3\n",
    "    data.loc[:,'AM3'] = AM3\n",
    "\n",
    "    return data\n",
    "\n",
    "#getPerformanceOfLast3Matches(training_data)\n",
    "#print(training_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>Referee</th>\n      <th>...</th>\n      <th>HCGD</th>\n      <th>ACGD</th>\n      <th>HAGD</th>\n      <th>AAGD</th>\n      <th>HM1</th>\n      <th>AM1</th>\n      <th>HM2</th>\n      <th>AM2</th>\n      <th>HM3</th>\n      <th>AM3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2008-08-16</td>\n      <td>Arsenal</td>\n      <td>West Brom</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>H Webb</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2008-08-16</td>\n      <td>Bolton</td>\n      <td>Stoke</td>\n      <td>3</td>\n      <td>1</td>\n      <td>H</td>\n      <td>3</td>\n      <td>0</td>\n      <td>H</td>\n      <td>C Foy</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2008-08-16</td>\n      <td>Everton</td>\n      <td>Blackburn</td>\n      <td>2</td>\n      <td>3</td>\n      <td>A</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>A Marriner</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2008-08-16</td>\n      <td>Hull</td>\n      <td>Fulham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>P Walton</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2008-08-16</td>\n      <td>Middlesbrough</td>\n      <td>Tottenham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>M Atkinson</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>4345</td>\n      <td>2019-12-14</td>\n      <td>Southampton</td>\n      <td>West Ham</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>M Atkinson</td>\n      <td>...</td>\n      <td>-17</td>\n      <td>-10</td>\n      <td>-0.894737</td>\n      <td>-0.526316</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>L</td>\n      <td>W</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>4346</td>\n      <td>2019-12-15</td>\n      <td>Man United</td>\n      <td>Everton</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>M Oliver</td>\n      <td>...</td>\n      <td>6</td>\n      <td>-9</td>\n      <td>0.315789</td>\n      <td>-0.473684</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>L</td>\n      <td>D</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>4347</td>\n      <td>2019-12-15</td>\n      <td>Wolves</td>\n      <td>Tottenham</td>\n      <td>1</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>S Attwell</td>\n      <td>...</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.210526</td>\n      <td>0.368421</td>\n      <td>D</td>\n      <td>W</td>\n      <td>W</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>4348</td>\n      <td>2019-12-15</td>\n      <td>Arsenal</td>\n      <td>Man City</td>\n      <td>0</td>\n      <td>3</td>\n      <td>A</td>\n      <td>0</td>\n      <td>3</td>\n      <td>A</td>\n      <td>P Tierney</td>\n      <td>...</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0.000000</td>\n      <td>1.315789</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <td>4349</td>\n      <td>2019-12-16</td>\n      <td>Crystal Palace</td>\n      <td>Brighton</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>C Pawson</td>\n      <td>...</td>\n      <td>-4</td>\n      <td>-4</td>\n      <td>-0.210526</td>\n      <td>-0.210526</td>\n      <td>D</td>\n      <td>D</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>4350 rows × 36 columns</p>\n</div>",
      "text/plain": "           Date        HomeTeam   AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n0    2008-08-16         Arsenal  West Brom     1     0   H     1     0   H   \n1    2008-08-16          Bolton      Stoke     3     1   H     3     0   H   \n2    2008-08-16         Everton  Blackburn     2     3   A     1     1   D   \n3    2008-08-16            Hull     Fulham     2     1   H     1     1   D   \n4    2008-08-16   Middlesbrough  Tottenham     2     1   H     0     0   D   \n...         ...             ...        ...   ...   ...  ..   ...   ...  ..   \n4345 2019-12-14     Southampton   West Ham     0     1   A     0     1   A   \n4346 2019-12-15      Man United    Everton     1     1   D     0     1   A   \n4347 2019-12-15          Wolves  Tottenham     1     2   A     0     1   A   \n4348 2019-12-15         Arsenal   Man City     0     3   A     0     3   A   \n4349 2019-12-16  Crystal Palace   Brighton     1     1   D     0     0   D   \n\n         Referee  ...  HCGD  ACGD      HAGD      AAGD   HM1   AM1   HM2   AM2  \\\n0         H Webb  ...     0     0  0.000000  0.000000  None  None  None  None   \n1          C Foy  ...     0     0  0.000000  0.000000  None  None  None  None   \n2     A Marriner  ...     0     0  0.000000  0.000000  None  None  None  None   \n3       P Walton  ...     0     0  0.000000  0.000000  None  None  None  None   \n4     M Atkinson  ...     0     0  0.000000  0.000000  None  None  None  None   \n...          ...  ...   ...   ...       ...       ...   ...   ...   ...   ...   \n4345  M Atkinson  ...   -17   -10 -0.894737 -0.526316     L     L     W     L   \n4346    M Oliver  ...     6    -9  0.315789 -0.473684     W     W     W     L   \n4347   S Attwell  ...     4     7  0.210526  0.368421     D     W     W     L   \n4348   P Tierney  ...     0    25  0.000000  1.315789     W     L     L     W   \n4349    C Pawson  ...    -4    -4 -0.210526 -0.210526     D     D     W     W   \n\n       HM3   AM3  \n0     None  None  \n1     None  None  \n2     None  None  \n3     None  None  \n4     None  None  \n...    ...   ...  \n4345     W     W  \n4346     D     L  \n4347     D     W  \n4348     D     D  \n4349     W     L  \n\n[4350 rows x 36 columns]"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----create features-----\n",
    "\n",
    "getDistance(training_data,geometricData)\n",
    "\n",
    "unifyDate(training_data)\n",
    "getMW(training_data,2008)\n",
    "getDeltaTime(training_data)\n",
    "getCumulativeGoalsDiff(training_data)\n",
    "getAverageGD(training_data)\n",
    "getPerformanceOfLast3Matches(training_data)\n",
    "\n",
    "training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- 删除中间数据 -----------------\n",
    "# !!!【在notebook中不写成函数，直接写里面的代码】\n",
    "def removeIntermediateData(data):   # or removeUnwantedData(data)\n",
    "    data = data[data.MW > 3]\n",
    "    \n",
    "    data = removeInvalidData(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "training_data = removeIntermediateData(training_data)\n",
    "\n",
    "# (--------------- Progress Summary -----------------)\n",
    "\n",
    "# !!!【不必写成函数；重点是给一个总结，并且说明feature是28个，因为FTR是标签不是feature】\n",
    "def printOutSummary(data):\n",
    "    n_matches = data.shape[0]\n",
    "    n_features = data.shape[1] - 1  # FTR is a label, not feature\n",
    "\n",
    "    print(\"total number of matches: {}\".format(n_matches))\n",
    "    print(\"number of features: {}\".format(n_features)) \n",
    "    print(\"home team win rate: {}\".format(checkAverageWinRate(training_data,'H')))\n",
    "    # print (\"away team xxxxxxxx\")\n",
    "    # print (\"draw xxxxxxxx\")\n",
    "\n",
    "#results of processed data:\n",
    "#total number of matches = 3981\n",
    "#number of features = 28  \n",
    "#home team = 0.4654609394624466 ~ 0.4655; \n",
    "#away team = 0.2868625973373524 ~ 0.2869;\n",
    "#draw = 0.24767646320020095 ~ 0.2477\n",
    "\n",
    "# !!!【 in report: From these results, we can find that the processed data is still imbalanced. We chose to make it binary.】\n",
    "\n",
    "# --------------- Data Transformation -----------------\n",
    "# ********************************\n",
    "data = training_data.copy()\n",
    "data.drop(['Date','HomeTeam', 'AwayTeam', 'Referee','FTHG', 'FTAG', 'MW'],1, inplace=True)\n",
    "\n",
    "# ********************************\n",
    "# simplify to a binary problem, make the target be FTR == 'H'\n",
    "def simplifyLabel(label):\n",
    "    if label == 'H':\n",
    "        return 'H'\n",
    "    else:\n",
    "        return 'NH'\n",
    "\n",
    "#data['FTR'] = data.FTR.apply(simplifyLabel)\n",
    "#data['HTR'] = data.HTR.apply(simplifyLabel)\n",
    "\n",
    "# ********************************\n",
    "# separate the training data into : feature set, label\n",
    "X_all = data.drop(['FTR'],1)\n",
    "Y_all = data['FTR']\n",
    "\n",
    "# map the label into 0, 1, 2 [multi-class classification]\n",
    "multiR = {'H':1, 'A':0, 'D':2}\n",
    "Y_all_multi = Y_all.map(d)\n",
    "\n",
    "'''\n",
    "# map the label into 0, 1 [binary class classification]\n",
    "Y_all_bi = Y_all.FTR.apply(simplifyLabel)\n",
    "biR = {'NH':0,'H':1}\n",
    "Y_all_bi = Y_all_bi.map(biR)\n",
    "'''\n",
    "\n",
    "# separate the columns in feature set by types: \n",
    "categList = [\"HTR\", \"HM1\",\"AM1\", \"HM2\",\"AM2\", \"HM3\",\"AM3\"]\n",
    "numList = list(set(X_all.columns.tolist()).difference(set(categList)))\n",
    "\n",
    "\n",
    "# ********************************\n",
    "# rescale data\n",
    "def rescale(data, cols):\n",
    "    for col in cols:\n",
    "        max = data[col].max()\n",
    "        min = data[col].min()\n",
    "        data[col] = (data[col] - min) / (max - min)\n",
    "    return data\n",
    "\n",
    "rescale(X_all,numList)   #[not sure if needed to be the whole numList]\n",
    "\n",
    "# ********************************\n",
    "# standardization\n",
    "from sklearn.preprocessing import scale\n",
    "def standardize(data,cols):\n",
    "    for col in cols:\n",
    "        data[col] = scale(data[col])\n",
    "\n",
    "standardize(X_all, numList)\n",
    "\n",
    "# ********************************\n",
    "# transform categorical features\n",
    "def transformCategoricalFeature(data,categoricalFeatureNames):\n",
    "    # 把这些特征转换成字符串类型\n",
    "    for col in categoricalFeatureNames:\n",
    "        data[col] = data[col].astype('str')\n",
    "    \n",
    "    output = pd.DataFrame(index=data.index)\n",
    "\n",
    "    for col_name, col_data in data.iteritems():\n",
    "        if col_data.dtype == 'object':\n",
    "            col_data = pd.get_dummies(col_data, prefix = col_name)\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = transformCategoricalFeature(X_all, categList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all[X_all.HTR_A == 1].HTR_A\n",
    "#data.AM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Visualization -----------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ************************************\n",
    "# plot all the features with Pearson correlation heatmap\n",
    "def plotGraph(X_all, Y_all):\n",
    "\n",
    "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
    "\n",
    "    colormap = plt.cm.RdBu\n",
    "    plt.figure(figsize=(21,18))\n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "    sns.heatmap(train_data.astype(float).corr(),linewidths=0.1,vmax=1.0,\n",
    "                square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "\n",
    "# plotGraph(X_all, Y_all)\n",
    "# !!!【in report: found that HAGD & HCGD, AAGD & ACGD are highly correlated, so drop HCGD, ACGD】\n",
    "# X_all = X_all.drop([\"HCGD\",\"ACGD\"], axis=1)\n",
    "\n",
    "# *************************************\n",
    "# plot the top 10 features related to FTR\n",
    "def plotGraph2(X_all, Y_all):\n",
    "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
    "\n",
    "    #FTR correlation matrix\n",
    "    plt.figure(figsize=(14,12))\n",
    "    k = 10 # number of variables for heatmap\n",
    "    cols = abs(train_data.astype(float).corr()).nlargest(k, 'FTR')['FTR'].index\n",
    "    cm = np.corrcoef(train_data[cols].values.T)\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plotGraph2(X_all, Y_all)\n",
    "# !!! 【in report: give a few comment of this graph】\n",
    "\n",
    "# X_all = X_all[\"A\", \"B\", \"C\", xxxx] \n",
    "# select the top 10 features according to the graph2, drop others\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfor clf in clfs:\\n    train_predict(clf, X_train, y_train, X_test, y_test)\\n    print(\"\\n\")\\n'"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- Classifiers ------------------------- \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf1 = GaussianNB()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2 = LogisticRegression(solver='lbfgs', multi_class = 'multinomial')\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "clf3 = LDA()\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "clf4 = QDA()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf5 = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf6 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "clfs = [clf1, clf2, clf3, clf4, clf5, clf6]\n",
    "\n",
    "\n",
    "# -------------------- Evaluation ------------------------- \n",
    "# ********************************\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, Y_all, test_size = 50,random_state = 2,stratify = Y_all)\n",
    "\n",
    "# ********************************\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "# train classifier\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    print(\"time for training: {:.4f} sec\".format(end - start))\n",
    "\n",
    "# predict using the classifier\n",
    "def predict_labels(clf, features, target):\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    print(\"time for prediction: {:.4f} sec\".format(end - start))\n",
    "    return f1_score(target, y_pred, pos_label=1, average=\"weighted\"), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "# print out the performance of each classifer\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    print(\"Classifier: {} [sample size: {}]\".format(clf.__class__.__name__, len(X_train)))\n",
    "\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "\n",
    "    # evaluate model on train set\n",
    "    print(\"[on train set]\")\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(\"F1 score: {:.4f} \".format(f1))\n",
    "    print(\"accuracy: {:.4f}\".format(acc))\n",
    "\n",
    "    # evaluate model on test set\n",
    "    print(\"[on test set]\")\n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score: {:.4f} \".format(f1))\n",
    "    print(\"accuracy: {:.4f}\".format(acc))\n",
    "\n",
    "'''\n",
    "for clf in clfs:\n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    print(\"\\n\")\n",
    "'''\n",
    "# [in report: xxx takes the shortest time for training; xxx has the highest accuracy; xxx [give comments to the result]]\n",
    "# [in report: so we choose to adjust xxxx (the relatively best one among them) with hyperparameters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classifier: LogisticRegression [sample size: 3931]\ntime for training: 0.0580 sec\n[on train set]\ntime for prediction: 0.0014 sec\nF1 score: 0.6480 \naccuracy: 0.6640\n[on test set]\ntime for prediction: 0.0008 sec\nF1 score: 0.6318 \naccuracy: 0.6800\n\n\nClassifier: LogisticRegression [sample size: 3931]\ntime for training: 0.0963 sec\n[on train set]\ntime for prediction: 0.0014 sec\nF1 score: 0.6484 \naccuracy: 0.6642\n[on test set]\ntime for prediction: 0.0011 sec\nF1 score: 0.6318 \naccuracy: 0.6800\n"
    }
   ],
   "source": [
    "\n",
    "#xtrain = X_train.copy()\n",
    "#xtest = X_test.copy()\n",
    "'''\n",
    "for clf in clfs:\n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    print(\"\\n\")\n",
    "'''\n",
    "#xtrain = xtrain[[\"DIS\",\"HDT\",\"ADT\", \"HCGD\", \"ACGD\", \"HAGD\", \"AAGD\", \"HM1_L\", \"HM2_L\", \"HM3_L\",\"AM1_L\", \"AM2_L\", \"AM3_L\", \"HM1_W\", \"HM2_W\", \"HM3_W\",\"AM1_W\", \"AM2_W\", \"AM3_W\", \"HM1_D\", \"HM2_D\", \"HM3_D\",\"AM1_D\", \"AM2_D\", \"AM3_D\"]]\n",
    "#xtest = xtest[[\"DIS\",\"HDT\",\"ADT\", \"HCGD\", \"ACGD\", \"HAGD\", \"AAGD\", \"HM1_L\", \"HM2_L\", \"HM3_L\",\"AM1_L\", \"AM2_L\", \"AM3_L\", \"HM1_W\", \"HM2_W\", \"HM3_W\",\"AM1_W\", \"AM2_W\", \"AM3_W\", \"HM1_D\", \"HM2_D\", \"HM3_D\",\"AM1_D\", \"AM2_D\", \"AM3_D\"]]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "# adjust the model with hyperparameter      【如果只一个model的话可以不用写成函数】\n",
    "def adjustClassifier(clf, f1_scorer, param, X_train, y_train):\n",
    "\n",
    "    grid_obj = GridSearchCV(clf,scoring=f1_scorer,param_grid=param,cv=5)\n",
    "    grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "    clf = grid_obj.best_estimator_\n",
    "\n",
    "    return clf\n",
    "\n",
    "clf = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial')\n",
    "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
    "parameters = { \n",
    "              'C' :[1.0, 100.0, 1000.0],\n",
    "              'max_iter':[100,200,300, 400, 500],\n",
    "              'intercept_scaling':[0.1, 0.5, 1.0]\n",
    "             }\n",
    "clf = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
    "\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2 = LogisticRegression(solver='lbfgs', multi_class = 'multinomial')\n",
    "\n",
    "train_predict(clf2, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Derive Feature of Test Sample --------------------\n",
    "# 把test sample里的名字查出，在此之前的比赛的各特征的平均值，distance现场算出\n",
    "\n",
    "# read data\n",
    "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/epl-test.csv'\n",
    "rawData_toPred = pd.read_csv(url)\n",
    "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/2019EPL.csv'\n",
    "preData2019 = pd.read_csv(url)\n",
    "\n",
    "# join the two dataframe together\n",
    "data2019 = pd.concat([preData_2019,X_sample],ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawData_toPred)\n",
    "print(preData2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>Referee</th>\n      <th>...</th>\n      <th>HCGD</th>\n      <th>ACGD</th>\n      <th>HAGD</th>\n      <th>AAGD</th>\n      <th>HM1</th>\n      <th>AM1</th>\n      <th>HM2</th>\n      <th>AM2</th>\n      <th>HM3</th>\n      <th>AM3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2019-08-09</td>\n      <td>Liverpool</td>\n      <td>Norwich</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>H</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>H</td>\n      <td>M Oliver</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2019-08-10</td>\n      <td>West Ham</td>\n      <td>Man City</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>A</td>\n      <td>M Dean</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2019-08-10</td>\n      <td>Bournemouth</td>\n      <td>Sheffield United</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>D</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>K Friend</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2019-08-10</td>\n      <td>Burnley</td>\n      <td>Southampton</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>G Scott</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2019-08-10</td>\n      <td>Crystal Palace</td>\n      <td>Everton</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>J Moss</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>2020-01-11</td>\n      <td>Leicester</td>\n      <td>Southampton</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>27.0</td>\n      <td>-13.0</td>\n      <td>1.173913</td>\n      <td>-0.565217</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>D</td>\n      <td>L</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>2020-01-11</td>\n      <td>Man United</td>\n      <td>Norwich</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>-19.0</td>\n      <td>0.304348</td>\n      <td>-0.826087</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>D</td>\n      <td>W</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>2020-01-11</td>\n      <td>Sheffield United</td>\n      <td>West Ham</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>-7.0</td>\n      <td>0.086957</td>\n      <td>-0.304348</td>\n      <td>L</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n      <td>D</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>2020-01-11</td>\n      <td>Tottenham</td>\n      <td>Liverpool</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>35.0</td>\n      <td>0.260870</td>\n      <td>1.521739</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>2020-01-11</td>\n      <td>Wolves</td>\n      <td>Newcastle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>-13.0</td>\n      <td>0.130435</td>\n      <td>-0.565217</td>\n      <td>L</td>\n      <td>L</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>219 rows × 36 columns</p>\n</div>",
      "text/plain": "          Date          HomeTeam          AwayTeam  FTHG  FTAG  FTR  HTHG  \\\n0   2019-08-09         Liverpool           Norwich   4.0   1.0    H   4.0   \n1   2019-08-10          West Ham          Man City   0.0   5.0    A   0.0   \n2   2019-08-10       Bournemouth  Sheffield United   1.0   1.0    D   0.0   \n3   2019-08-10           Burnley       Southampton   3.0   0.0    H   0.0   \n4   2019-08-10    Crystal Palace           Everton   0.0   0.0    D   0.0   \n..         ...               ...               ...   ...   ...  ...   ...   \n214 2020-01-11         Leicester       Southampton   NaN   NaN  NaN   NaN   \n215 2020-01-11        Man United           Norwich   NaN   NaN  NaN   NaN   \n216 2020-01-11  Sheffield United          West Ham   NaN   NaN  NaN   NaN   \n217 2020-01-11         Tottenham         Liverpool   NaN   NaN  NaN   NaN   \n218 2020-01-11            Wolves         Newcastle   NaN   NaN  NaN   NaN   \n\n     HTAG  HTR   Referee  ...  HCGD  ACGD      HAGD      AAGD   HM1   AM1  \\\n0     0.0    H  M Oliver  ...   0.0   0.0  0.000000  0.000000  None  None   \n1     1.0    A    M Dean  ...   0.0   0.0  0.000000  0.000000  None  None   \n2     0.0    D  K Friend  ...   0.0   0.0  0.000000  0.000000  None  None   \n3     0.0    D   G Scott  ...   0.0   0.0  0.000000  0.000000  None  None   \n4     0.0    D    J Moss  ...   0.0   0.0  0.000000  0.000000  None  None   \n..    ...  ...       ...  ...   ...   ...       ...       ...   ...   ...   \n214   NaN  NaN       NaN  ...  27.0 -13.0  1.173913 -0.565217     W     W   \n215   NaN  NaN       NaN  ...   7.0 -19.0  0.304348 -0.826087     L     D   \n216   NaN  NaN       NaN  ...   2.0  -7.0  0.086957 -0.304348     L     W   \n217   NaN  NaN       NaN  ...   6.0  35.0  0.260870  1.521739     L     W   \n218   NaN  NaN       NaN  ...   3.0 -13.0  0.130435 -0.565217     L     L   \n\n      HM2   AM2   HM3   AM3  \n0    None  None  None  None  \n1    None  None  None  None  \n2    None  None  None  None  \n3    None  None  None  None  \n4    None  None  None  None  \n..    ...   ...   ...   ...  \n214     W     D     L     W  \n215     W     D     W     L  \n216     L     L     D     L  \n217     D     W     W     W  \n218     L     L     W     L  \n\n[219 rows x 36 columns]"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "getDistance(training_data,geometricData)\n",
    "\n",
    "unifyDateFormat(training_data)\n",
    "getMW(training_data,2008)\n",
    "getDeltaTime(training_data)\n",
    "getCumulativeGoalsDiff(training_data)\n",
    "getAverageGD(training_data)\n",
    "getPerformanceOfLast3Matches(training_data)\n",
    "\n",
    "'''\n",
    "# derive feature\n",
    "unifyDate(data2019)\n",
    "getDistance(data2019,geometricData) # HomeTeam,AwayTeam -> DIS\n",
    "getMW(data2019,2019)    # Date -> MW\n",
    "getDeltaTime(data2019)  # Date -> HDT, ADT\n",
    "getCumulativeGoalsDiff(data2019)    # FTHG, FTAG -> HCGD, ACGD\n",
    "getAverageGD(data2019)      # HCGD, ACGD, MW -> HAGD, AAGD\n",
    "getPerformanceOfLast3Matches(data2019)  # FTR -> HM1, AM1, HM2, AM2, HM3, AM3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DIS</th>\n      <th>HDT</th>\n      <th>ADT</th>\n      <th>HCGD</th>\n      <th>ACGD</th>\n      <th>HAGD</th>\n      <th>AAGD</th>\n      <th>HM1</th>\n      <th>HM2</th>\n      <th>HM3</th>\n      <th>AM1</th>\n      <th>AM2</th>\n      <th>AM3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>300.215302</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>265.040710</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>297.773346</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>325.889374</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>299.905975</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>191.525848</td>\n      <td>10</td>\n      <td>10</td>\n      <td>27.0</td>\n      <td>-13.0</td>\n      <td>1.173913</td>\n      <td>-0.565217</td>\n      <td>W</td>\n      <td>W</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>258.923889</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7.0</td>\n      <td>-19.0</td>\n      <td>0.304348</td>\n      <td>-0.826087</td>\n      <td>L</td>\n      <td>W</td>\n      <td>W</td>\n      <td>D</td>\n      <td>D</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>230.038284</td>\n      <td>9</td>\n      <td>10</td>\n      <td>2.0</td>\n      <td>-7.0</td>\n      <td>0.086957</td>\n      <td>-0.304348</td>\n      <td>L</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>282.755493</td>\n      <td>10</td>\n      <td>9</td>\n      <td>6.0</td>\n      <td>35.0</td>\n      <td>0.260870</td>\n      <td>1.521739</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>267.589935</td>\n      <td>10</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>-13.0</td>\n      <td>0.130435</td>\n      <td>-0.565217</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>219 rows × 13 columns</p>\n</div>",
      "text/plain": "            DIS  HDT  ADT  HCGD  ACGD      HAGD      AAGD   HM1   HM2   HM3  \\\n0    300.215302    0    0   0.0   0.0  0.000000  0.000000  None  None  None   \n1    265.040710    0    0   0.0   0.0  0.000000  0.000000  None  None  None   \n2    297.773346    0    0   0.0   0.0  0.000000  0.000000  None  None  None   \n3    325.889374    0    0   0.0   0.0  0.000000  0.000000  None  None  None   \n4    299.905975    0    0   0.0   0.0  0.000000  0.000000  None  None  None   \n..          ...  ...  ...   ...   ...       ...       ...   ...   ...   ...   \n214  191.525848   10   10  27.0 -13.0  1.173913 -0.565217     W     W     L   \n215  258.923889   10   10   7.0 -19.0  0.304348 -0.826087     L     W     W   \n216  230.038284    9   10   2.0  -7.0  0.086957 -0.304348     L     L     D   \n217  282.755493   10    9   6.0  35.0  0.260870  1.521739     L     D     W   \n218  267.589935   10   10   3.0 -13.0  0.130435 -0.565217     L     L     W   \n\n      AM1   AM2   AM3  \n0    None  None  None  \n1    None  None  None  \n2    None  None  None  \n3    None  None  None  \n4    None  None  None  \n..    ...   ...   ...  \n214     W     D     W  \n215     D     D     L  \n216     W     L     L  \n217     W     W     W  \n218     L     L     L  \n\n[219 rows x 13 columns]"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select feature\n",
    "l = [\"DIS\",\"HDT\",\"ADT\", \"HCGD\", \"ACGD\", \"HAGD\", \"AAGD\", \"HM1\", \"HM2\", \"HM3\",\"AM1\", \"AM2\", \"AM3\"]\n",
    "data2019_selectedFeature = data2019[l]\n",
    "data2019_selectedFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DIS</th>\n      <th>HDT</th>\n      <th>ADT</th>\n      <th>HCGD</th>\n      <th>ACGD</th>\n      <th>HAGD</th>\n      <th>AAGD</th>\n      <th>HM1</th>\n      <th>HM2</th>\n      <th>HM3</th>\n      <th>AM1</th>\n      <th>AM2</th>\n      <th>AM3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>30</td>\n      <td>291.123566</td>\n      <td>7</td>\n      <td>7</td>\n      <td>-2.0</td>\n      <td>3.0</td>\n      <td>-0.500000</td>\n      <td>0.750000</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>228.692932</td>\n      <td>7</td>\n      <td>7</td>\n      <td>-3.0</td>\n      <td>0.0</td>\n      <td>-0.750000</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>D</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>174.849289</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.000000</td>\n      <td>-0.250000</td>\n      <td>W</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>217.818192</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>0.250000</td>\n      <td>-0.250000</td>\n      <td>W</td>\n      <td>D</td>\n      <td>D</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>325.604492</td>\n      <td>6</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>1.750000</td>\n      <td>0.250000</td>\n      <td>W</td>\n      <td>D</td>\n      <td>W</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>191.525848</td>\n      <td>10</td>\n      <td>10</td>\n      <td>27.0</td>\n      <td>-13.0</td>\n      <td>1.173913</td>\n      <td>-0.565217</td>\n      <td>W</td>\n      <td>W</td>\n      <td>L</td>\n      <td>W</td>\n      <td>D</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>258.923889</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7.0</td>\n      <td>-19.0</td>\n      <td>0.304348</td>\n      <td>-0.826087</td>\n      <td>L</td>\n      <td>W</td>\n      <td>W</td>\n      <td>D</td>\n      <td>D</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>230.038284</td>\n      <td>9</td>\n      <td>10</td>\n      <td>2.0</td>\n      <td>-7.0</td>\n      <td>0.086957</td>\n      <td>-0.304348</td>\n      <td>L</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>282.755493</td>\n      <td>10</td>\n      <td>9</td>\n      <td>6.0</td>\n      <td>35.0</td>\n      <td>0.260870</td>\n      <td>1.521739</td>\n      <td>L</td>\n      <td>D</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>267.589935</td>\n      <td>10</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>-13.0</td>\n      <td>0.130435</td>\n      <td>-0.565217</td>\n      <td>L</td>\n      <td>L</td>\n      <td>W</td>\n      <td>L</td>\n      <td>L</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>189 rows × 13 columns</p>\n</div>",
      "text/plain": "            DIS  HDT  ADT  HCGD  ACGD      HAGD      AAGD HM1 HM2 HM3 AM1 AM2  \\\n30   291.123566    7    7  -2.0   3.0 -0.500000  0.750000   W   L   L   L   D   \n31   228.692932    7    7  -3.0   0.0 -0.750000  0.000000   W   D   L   L   W   \n32   174.849289    7    8   0.0  -1.0  0.000000 -0.250000   W   L   D   W   L   \n33   217.818192    7    6   1.0  -1.0  0.250000 -0.250000   W   D   D   L   W   \n34   325.604492    6    7   7.0   1.0  1.750000  0.250000   W   D   W   L   D   \n..          ...  ...  ...   ...   ...       ...       ...  ..  ..  ..  ..  ..   \n214  191.525848   10   10  27.0 -13.0  1.173913 -0.565217   W   W   L   W   D   \n215  258.923889   10   10   7.0 -19.0  0.304348 -0.826087   L   W   W   D   D   \n216  230.038284    9   10   2.0  -7.0  0.086957 -0.304348   L   L   D   W   L   \n217  282.755493   10    9   6.0  35.0  0.260870  1.521739   L   D   W   W   W   \n218  267.589935   10   10   3.0 -13.0  0.130435 -0.565217   L   L   W   L   L   \n\n    AM3  \n30    W  \n31    D  \n32    L  \n33    D  \n34    W  \n..   ..  \n214   W  \n215   L  \n216   L  \n217   W  \n218   L  \n\n[189 rows x 13 columns]"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove data containing empty value\n",
    "data2019_removeEmpty = removeInvalidData(data2019_selectedFeature)\n",
    "data2019_removeEmpty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DIS</th>\n      <th>HDT</th>\n      <th>ADT</th>\n      <th>HCGD</th>\n      <th>ACGD</th>\n      <th>HAGD</th>\n      <th>AAGD</th>\n      <th>HM1_D</th>\n      <th>HM1_L</th>\n      <th>HM1_W</th>\n      <th>...</th>\n      <th>HM3_W</th>\n      <th>AM1_D</th>\n      <th>AM1_L</th>\n      <th>AM1_W</th>\n      <th>AM2_D</th>\n      <th>AM2_L</th>\n      <th>AM2_W</th>\n      <th>AM3_D</th>\n      <th>AM3_L</th>\n      <th>AM3_W</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>30</td>\n      <td>1.082232</td>\n      <td>-0.100742</td>\n      <td>-0.127943</td>\n      <td>-0.172498</td>\n      <td>0.282329</td>\n      <td>-0.688127</td>\n      <td>1.056763</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.485296</td>\n      <td>-0.100742</td>\n      <td>-0.127943</td>\n      <td>-0.263312</td>\n      <td>0.000000</td>\n      <td>-1.040985</td>\n      <td>-0.009968</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>-0.029534</td>\n      <td>-0.100742</td>\n      <td>0.159929</td>\n      <td>0.009129</td>\n      <td>-0.094110</td>\n      <td>0.017590</td>\n      <td>-0.365544</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.381316</td>\n      <td>-0.100742</td>\n      <td>-0.415816</td>\n      <td>0.099943</td>\n      <td>-0.094110</td>\n      <td>0.370449</td>\n      <td>-0.365544</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.411924</td>\n      <td>-0.389229</td>\n      <td>-0.127943</td>\n      <td>0.644825</td>\n      <td>0.094110</td>\n      <td>2.487600</td>\n      <td>0.345609</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>0.129920</td>\n      <td>0.764721</td>\n      <td>0.735674</td>\n      <td>2.461098</td>\n      <td>-1.223424</td>\n      <td>1.674491</td>\n      <td>-0.813880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.774352</td>\n      <td>0.764721</td>\n      <td>0.735674</td>\n      <td>0.644825</td>\n      <td>-1.788081</td>\n      <td>0.447157</td>\n      <td>-1.184917</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>0.498160</td>\n      <td>0.476233</td>\n      <td>0.735674</td>\n      <td>0.190757</td>\n      <td>-0.658767</td>\n      <td>0.140324</td>\n      <td>-0.442844</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>1.002220</td>\n      <td>0.764721</td>\n      <td>0.447801</td>\n      <td>0.554011</td>\n      <td>3.293834</td>\n      <td>0.385791</td>\n      <td>2.154413</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0.857213</td>\n      <td>0.764721</td>\n      <td>0.735674</td>\n      <td>0.281570</td>\n      <td>-1.223424</td>\n      <td>0.201690</td>\n      <td>-0.813880</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>189 rows × 25 columns</p>\n</div>",
      "text/plain": "          DIS       HDT       ADT      HCGD      ACGD      HAGD      AAGD  \\\n30   1.082232 -0.100742 -0.127943 -0.172498  0.282329 -0.688127  1.056763   \n31   0.485296 -0.100742 -0.127943 -0.263312  0.000000 -1.040985 -0.009968   \n32  -0.029534 -0.100742  0.159929  0.009129 -0.094110  0.017590 -0.365544   \n33   0.381316 -0.100742 -0.415816  0.099943 -0.094110  0.370449 -0.365544   \n34   1.411924 -0.389229 -0.127943  0.644825  0.094110  2.487600  0.345609   \n..        ...       ...       ...       ...       ...       ...       ...   \n214  0.129920  0.764721  0.735674  2.461098 -1.223424  1.674491 -0.813880   \n215  0.774352  0.764721  0.735674  0.644825 -1.788081  0.447157 -1.184917   \n216  0.498160  0.476233  0.735674  0.190757 -0.658767  0.140324 -0.442844   \n217  1.002220  0.764721  0.447801  0.554011  3.293834  0.385791  2.154413   \n218  0.857213  0.764721  0.735674  0.281570 -1.223424  0.201690 -0.813880   \n\n     HM1_D  HM1_L  HM1_W  ...  HM3_W  AM1_D  AM1_L  AM1_W  AM2_D  AM2_L  \\\n30       0      0      1  ...      0      0      1      0      1      0   \n31       0      0      1  ...      0      0      1      0      0      0   \n32       0      0      1  ...      0      0      0      1      0      1   \n33       0      0      1  ...      0      0      1      0      0      0   \n34       0      0      1  ...      1      0      1      0      1      0   \n..     ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n214      0      0      1  ...      0      0      0      1      1      0   \n215      0      1      0  ...      1      1      0      0      1      0   \n216      0      1      0  ...      0      0      0      1      0      1   \n217      0      1      0  ...      1      0      0      1      0      0   \n218      0      1      0  ...      1      0      1      0      0      1   \n\n     AM2_W  AM3_D  AM3_L  AM3_W  \n30       0      0      0      1  \n31       1      1      0      0  \n32       0      0      1      0  \n33       1      1      0      0  \n34       0      0      0      1  \n..     ...    ...    ...    ...  \n214      0      0      0      1  \n215      0      0      1      0  \n216      0      0      1      0  \n217      1      0      0      1  \n218      0      0      1      0  \n\n[189 rows x 25 columns]"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data transformation\n",
    "numList1 = [\"DIS\",\"HDT\",\"ADT\", \"HCGD\", \"ACGD\", \"HAGD\", \"AAGD\"]\n",
    "rescale(data2019_selectedFeature,numList1)   \n",
    "standardize(data2019_selectedFeature, numList1)\n",
    "\n",
    "categList1 = [\"HM1\", \"HM2\", \"HM3\",\"AM1\", \"AM2\", \"AM3\"]\n",
    "data2019_selectedFeature = transformCategoricalFeature(data2019_selectedFeature, categList1)\n",
    "data2019_selectedFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "time for training: 0.1022 sec\n[1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0\n 1 0 0 2 1 1 1 0 1 1 1 0 1 0 1 1 2 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1\n 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0\n 1 0 2 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 2 1 1 1 1 1 0 0 1 1 0 0 1 1\n 1 0 1 1 1 2 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0]\n\n\n[0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1\n 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0\n 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1\n 1 1 0 1]\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-0239fd2d987d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_2019InTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "train_classifier(clf2,xtrain,y_train)     # train the classifer\n",
    "sample = data2019_selectedFeature.tail(10)\n",
    "sample1 = xtest.sample(n=10, random_state=1)\n",
    "sample2 = data2019_selectedFeature\n",
    "sample3 = xtrain.tail(179)\n",
    "\n",
    "y_pred_2019InTrain = clf2.predict(sample3)\n",
    "print(y_pred_2019InTrain)\n",
    "\n",
    "print(\"\\n\")\n",
    "y_pred_2019Data = clf2.predict(sample2)\n",
    "print(y_pred_2019Data)\n",
    "len(sample2)\n",
    "\n",
    "def foo(x):\n",
    "    if x == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(y_pred_2019InTrain.map({0:0,1:0,2:1}).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=0.1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n"
    }
   ],
   "source": [
    "print(clf)      #调过参数后\n",
    "print(clf2)    #普通"
   ]
  }
 ]
}