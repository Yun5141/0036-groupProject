{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FootballResultPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "outputs": [],
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yun5141/comp0036/blob/master/FootballResultPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RbwPTMh0lmA6"
      },
      "outputs": [],
      "source": [
        "# 1. Introduction [*Terry*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lNNXxH5mSMN"
      },
      "outputs": [],
      "source": [
        "# 2. Data Import  [*Yun*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8kND_qBXNFx1"
      },
      "outputs": [],
      "source": [
        "We first import all the packages that will be used in the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "n1q0F9DFNFx2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "#!pip3 install geopy\n",
        "from geopy.distance import geodesic \n",
        "from geopy.distance import great_circle \n",
        "\n",
        "#!pip3 install sklearn\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hGAQYyhMNFx5"
      },
      "outputs": [],
      "source": [
        "And then the data sets from our github repository (https://github.com/Yun5141/comp0036):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KB6sgvUmNFx6"
      },
      "outputs": [],
      "source": [
        "# training data set\n",
        "url=\"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-training.csv\"\n",
        "raw_training_data=pd.read_csv(url)\n",
        "\n",
        "# test set\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-test.csv'\n",
        "rawData_toPred = pd.read_csv(url)\n",
        "\n",
        "# 2019 up-to-date data (from http://www.football-data.co.uk)\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl2019.csv'\n",
        "rawData_2019_uptodate = pd.read_csv(url)\n",
        "\n",
        "# geometric information of teams\n",
        "# to calculate the distance needed to travel for the away team\n",
        "url = \"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/stadiums-with-GPS-coordinates.csv\"\n",
        "geometricData = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tnNgP1TpsS-c"
      },
      "outputs": [],
      "source": [
        "# 3. Data Transformation & Exploration [*Yun*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7B_FaFS_38OD"
      },
      "outputs": [],
      "source": [
        "### 3.1 Initial Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rYo2F4b0NFx-"
      },
      "outputs": [],
      "source": [
        "We first visualize the raw training data and find that:\n",
        "- The shape of the dataframe is 4180 rows x 73 columns, but some columns are empty and unamed.\n",
        "- There are two different date formats, \"%d/%m/%y\" and \"%d/%m/%Y\".\n",
        "- The involved data is from 2008-08-16 to 2019-05-12 (i.e. there are totally 11 seasons)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "colab_type": "code",
        "id": "23hh57O8NFx_",
        "outputId": "bc0f2713-edaa-42c0-f4ef-69fdbca68a10"
      },
      "outputs": [],
      "source": [
        "raw_training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "087tcJQoNFyE"
      },
      "outputs": [],
      "source": [
        "We drop the unamed columns and find now the shape of the dataframe is 4180 rows x 22 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "colab_type": "code",
        "id": "yny3d4baNFyF",
        "outputId": "6c5c7361-ca06-4296-eea6-24018bf96120"
      },
      "outputs": [],
      "source": [
        "raw_training_data = raw_training_data[raw_training_data.columns[~raw_training_data.columns.str.contains('Unnamed:')]]\n",
        "raw_training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ro6RH3StNFyH"
      },
      "outputs": [],
      "source": [
        "##### 3.1.1 Invalid data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dga6PjfrNFyI"
      },
      "outputs": [],
      "source": [
        "We then check if there are rows containing None, NaN, infinite or overflowed values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "W8VK3ZMyNFyJ",
        "outputId": "8fe2c56d-56b3-470d-a809-72176250599e"
      },
      "outputs": [],
      "source": [
        "def removeInvalidData(data):\n",
        "\n",
        "    # remove data which contains None\n",
        "    data.dropna(axis=0, how='any',inplace=True)\n",
        "\n",
        "    # remove data which contains NaN, infinite or overflowed number \n",
        "    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    data = data[indices_to_keep]\n",
        "\n",
        "    return data\n",
        "\n",
        "assert raw_training_data.shape[0] == removeInvalidData(raw_training_data).shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IZeNmgNNFyN"
      },
      "outputs": [],
      "source": [
        "The result indicates that there is no rows containing such values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GnAXcCh5NFyN"
      },
      "outputs": [],
      "source": [
        "##### 3.1.2 Number of matches per season"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AtdrUKgLNFyO"
      },
      "outputs": [],
      "source": [
        "The training set is of huge amount. To help learning the data, we separate the data set by seasons (from August to May) to see how many matches there are in each year.\n",
        "\n",
        "Before splitting the data set, we need to unify the date format first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "colab_type": "code",
        "id": "SxGeEyQqNFyP",
        "outputId": "e79b13bf-26f5-46cb-fc61-7227ab04d860"
      },
      "outputs": [],
      "source": [
        "# unify the different date formats and convert the type from str to timestamp  \n",
        "def unifyDate(data):\n",
        "\n",
        "    if not isinstance(data.Date[0],str):\n",
        "        return\n",
        "\n",
        "    newDate = []\n",
        "    for _, matchInfo in data.iterrows():\n",
        "        if len(matchInfo.Date) == 8 :\n",
        "            newDate.append( pd.to_datetime(matchInfo.Date, format=\"%d/%m/%y\" ))\n",
        "        elif len(matchInfo.Date) == 10 :\n",
        "            newDate.append(  pd.to_datetime(matchInfo.Date, format=\"%d/%m/%Y\" ))\n",
        "    \n",
        "    data['Date'] = pd.Series(newDate).values\n",
        "\n",
        "# to see the number of matches each year (season)\n",
        "def separateData(data):\n",
        "    dataframe_collection = {}\n",
        "\n",
        "    for year in range(2008, 2019):\n",
        "        dataframe_collection[year] = data[(data.Date > dt.datetime(year,8,1,0,0) ) & (data.Date < dt.datetime(year+1, 6, 1,0,0))]\n",
        "\n",
        "    return dataframe_collection\n",
        "\n",
        "unifyDate(raw_training_data)\n",
        "collection = separateData(raw_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "hn89z46XNFyQ",
        "outputId": "1a80c3d7-062b-4f01-a9c0-d583dd68d2b3"
      },
      "outputs": [],
      "source": [
        "for key in collection.keys():\n",
        "    print(\"{} [{} rows x {} columns]\".format(key,collection[key].shape[0],collection[key].shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EG9OBuM5NFyS"
      },
      "outputs": [],
      "source": [
        "The result shows that the number of matches each season stays the same (380 matches per season)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zte3G2-BNFyT"
      },
      "outputs": [],
      "source": [
        "##### 3.1.3 Percentage of match result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TYl3kex0NFyT"
      },
      "outputs": [],
      "source": [
        "We compute the average percentage of each match result per season and also that over the 11 years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BY_5GpdkNFyU"
      },
      "outputs": [],
      "source": [
        "def getPercentageOfMatchResult(data, matchResult):\n",
        "\n",
        "    if matchResult not in ['H', 'A', 'D']:\n",
        "        raise Exception('The second argument should only take values within [“H”,“A”,“D”]')\n",
        "    \n",
        "    n_wins = len(data[data.FTR == matchResult])\n",
        "\n",
        "    return n_wins / data.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "V93W0nqfNFyW",
        "outputId": "1c712009-490e-4e9d-8326-bb92875f9602"
      },
      "outputs": [],
      "source": [
        "# the average percentage of each match result per season\n",
        "for key in collection.keys():\n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [{}]\".format(key,len(collection[key])))\n",
        "    print(\"-\"*40)\n",
        "    print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"H\")*100))\n",
        "    print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"A\")*100))\n",
        "    print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"D\")*100))\n",
        "\n",
        "# the average percentage over the 11 years\n",
        "print(\"\\n\" +\"=\"*40)\n",
        "print(\"Overall [{}]\".format(len(raw_training_data)))\n",
        "print(\"-\"*40)\n",
        "print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"H\")*100))\n",
        "print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"A\")*100))\n",
        "print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"D\")*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "43mHSTIoNFya"
      },
      "outputs": [],
      "source": [
        "From the result, we find that in all cases the result 'home team wins' is of the highest probability, and 'H':'A':'D' $\\approx$ 5:3:2 in general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gRlWYgxKNFyb"
      },
      "outputs": [],
      "source": [
        "##### 3.1.4 Relationship between attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Py97gHJvNFyc"
      },
      "outputs": [],
      "source": [
        "Now let's take a look at the attributes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "5R13hg3GNFyd",
        "outputId": "7d05551c-0689-4086-dcac-74600f85960d"
      },
      "outputs": [],
      "source": [
        "raw_training_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kGF1QVGFNFyf"
      },
      "outputs": [],
      "source": [
        "We can plot a Pearson Correlation Heatmap to see the top 10 features related to the match result 'FTR':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "colab_type": "code",
        "id": "3FTQvYUANFyg",
        "outputId": "8cb4aed0-ae38-4b59-a37a-eeb0b5fff978"
      },
      "outputs": [],
      "source": [
        "# plot the top 10 features related to FTR\n",
        "def plotGraph(X_all, Y_all):\n",
        "\n",
        "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
        "\n",
        "    #FTR correlation matrix\n",
        "    plt.figure(figsize=(12,12))\n",
        "    k = 11 # number of variables for heatmap\n",
        "    cols = abs(train_data.astype(float).corr()).nlargest(k, 'FTR')['FTR'].index\n",
        "    cm = np.corrcoef(train_data[cols].values.T)\n",
        "    sns.set(font_scale=1.25)\n",
        "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 12}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "    plt.show()\n",
        "\n",
        "attributes = raw_training_data.drop(['Date','HomeTeam', 'AwayTeam', 'Referee','FTR'],1)\n",
        "attributes['HTR'] = attributes['HTR'].map({'H':1,'A':0,'D':2})\n",
        "label = raw_training_data['FTR']\n",
        "label = label.map({'H':1,'A':0,'D':2})\n",
        "plotGraph(attributes,label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzRcDr60NFyi"
      },
      "outputs": [],
      "source": [
        "As shown in the graph, the top 10 features are HTR, FTHG, HTHG, HST, HS, HR, AS, AST, HTAG,FTAG (ordered from the greatest to least). \n",
        "\n",
        "It is notable that the goal scored at full time (FTXG) & goal scored at half time (HTXG) and the total number of shots on goal (XS) & that on target (XST) are the two pairs of data which is highly correlated (>0.65).\n",
        "\n",
        "So within the top 10 we pick the following attributes to create features:\n",
        "- FTHG, FTAG -> the cumulative full time goal difference by home team and away team\n",
        "- HS, AS -> the average number of shots on goal in the past 3 matches by home team and away team\n",
        "- HR, AR (as features directly)\n",
        "\n",
        "Additionally, we derive features by using:\n",
        "- Date -> the delta time from last match of home team and away team\n",
        "- HomeTeam, AwayTeam -> the distance needed to travel for the away team (with the help of extra data source)\n",
        "- FTR -> the performance of past 3 matches of the home team and away team\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "--kHgA_HNFyi",
        "outputId": "584e5544-919a-4dad-fb7a-589c59019407"
      },
      "outputs": [],
      "source": [
        "selectedAttributes = [\"Date\",\"HomeTeam\", \"AwayTeam\",\"FTR\",\"FTHG\",\"FTAG\",\"HS\",\"AS\",\"HR\",\"AR\"]\n",
        "training_data = raw_training_data[selectedAttributes]\n",
        "training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4bC5O7w4J16"
      },
      "outputs": [],
      "source": [
        "### 3.2 Feature Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mjmXp8Y06enf"
      },
      "outputs": [],
      "source": [
        "##### 3.2.1 Cumulative full time goal difference by home team and away team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZMbyUF2CNFyl"
      },
      "outputs": [],
      "source": [
        "As we have found that the number of matches per season is always the same, we can simply use i % 380 == 0 to check if it is a new season and to initialize the goal difference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1APZ-dZ-NFym"
      },
      "outputs": [],
      "source": [
        "# calculate the cumulative goal difference (before the current match) scored by home team and away team  \n",
        "def getCumulativeGoalsDiff(data):\n",
        "    teams = {}\n",
        "    HCGD = [] \n",
        "    ACGD = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []\n",
        "\n",
        "        FTHG = data.iloc[i]['FTHG']\n",
        "        FTAG = data.iloc[i]['FTAG']\n",
        "\n",
        "        try:\n",
        "            cgd_h = teams[data.iloc[i].HomeTeam].pop()\n",
        "            cgd_a = teams[data.iloc[i].AwayTeam].pop()\n",
        "        except:\n",
        "            cgd_h = 0\n",
        "            cgd_a = 0\n",
        "\n",
        "        HCGD.append(cgd_h)\n",
        "        ACGD.append(cgd_a)\n",
        "        cgd_h = cgd_h + FTHG - FTAG\n",
        "        teams[data.iloc[i].HomeTeam].append(cgd_h)\n",
        "        cgd_a = cgd_a + FTAG - FTHG\n",
        "        teams[data.iloc[i].AwayTeam].append(cgd_a)\n",
        "\n",
        "    data.loc[:,'HCGD'] = pd.Series(HCGD)\n",
        "    data.loc[:,'ACGD'] = pd.Series(ACGD)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fAqg4IhANFyp"
      },
      "outputs": [],
      "source": [
        "##### 3.2.2 Average number of shots on goal in the past 3 matches by home team and away team"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MNlS0UYXNFyr"
      },
      "outputs": [],
      "source": [
        "# calculate the average number of shots on goal in the past 3 matches by home team and away team  \n",
        "def getAverageShotsOnGoalInPast3Matches(data):\n",
        "    teams = {}\n",
        "    HAHS = [] \n",
        "    AAHS = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None]) #[3rd, 2nd, latest data]\n",
        "\n",
        "        try:\n",
        "            ahs_h = np.mean(teams[data.iloc[i].HomeTeam])\n",
        "            ahs_a = np.mean(teams[data.iloc[i].AwayTeam])\n",
        "        except:\n",
        "            ahs_h = None\n",
        "            ahs_a = None\n",
        "\n",
        "        HAHS.append(ahs_h)\n",
        "        AAHS.append(ahs_a)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].popleft()\n",
        "        teams[data.iloc[i].HomeTeam].append(data.iloc[i].HS)\n",
        "\n",
        "        teams[data.iloc[i].AwayTeam].popleft()\n",
        "        teams[data.iloc[i].AwayTeam].append(data.iloc[i].AS)\n",
        "\n",
        "    data.loc[:,'HAHS'] = pd.Series(HAHS)\n",
        "    data.loc[:,'AAHS'] = pd.Series(AAHS)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q-4CgM2T5-G2"
      },
      "outputs": [],
      "source": [
        "##### 3.2.3 Delta time from last match for home team and away team  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XMuBcp-jNFyu"
      },
      "outputs": [],
      "source": [
        "# calculate the delta time from last match for home team and away team  [done]\n",
        "def getDeltaTime(data):\n",
        "    \n",
        "    teams = {}\n",
        "\n",
        "    HDT = []\n",
        "    ADT = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []    # to store last match date\n",
        "\n",
        "        currentDate = data.iloc[i].Date\n",
        "\n",
        "        try:\n",
        "            homeLastMatchDate = teams[data.iloc[i].HomeTeam].pop()\n",
        "            awayLastMatchDate = teams[data.iloc[i].AwayTeam].pop()\n",
        "\n",
        "            hdt = (currentDate - homeLastMatchDate).days\n",
        "            adt = (currentDate - awayLastMatchDate).days\n",
        "        except:\n",
        "            homeLastMatchDate = currentDate\n",
        "            awayLastMatchDate = currentDate\n",
        "\n",
        "            hdt = None\n",
        "            adt = None\n",
        "\n",
        "        HDT.append(hdt)\n",
        "        ADT.append(adt)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].append(currentDate)\n",
        "        teams[data.iloc[i].AwayTeam].append(currentDate)\n",
        "\n",
        "    data.loc[:,'HDT'] = HDT\n",
        "    data.loc[:,'ADT'] = ADT\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rzi4aEb35g3a"
      },
      "outputs": [],
      "source": [
        "##### 3.2.4 Distance needed to travel for the away team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XUNgVlWzNFyw"
      },
      "outputs": [],
      "source": [
        "The *geometricData* is an extra data source providing the latitude and longitude of teams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pjiPYvbNNFyx"
      },
      "outputs": [],
      "source": [
        "# get the distance needed to travel for the away team \n",
        "def getDistance(data, geometricData):\n",
        "  array = []\n",
        "  for x in data.iterrows():\n",
        "   \n",
        "    home_lat = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Latitude\n",
        "    home_long = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Longitude\n",
        "    home_location = (np.float32(home_lat), np.float32(home_long))\n",
        "    \n",
        "    away_lat = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Latitude\n",
        "   \n",
        "    away_long = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Longitude\n",
        "    away_location = (np.float32(away_lat), np.float32(away_long))\n",
        "    array.append(np.float32(geodesic(home_location, away_location).km))\n",
        "  \n",
        "  \n",
        "  DIS = pd.Series(array)\n",
        "  data.loc[:,'DIS'] = DIS\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8MHYpEE261SS"
      },
      "outputs": [],
      "source": [
        "##### 3.2.5 Performances of last 3 matches of home team and away team"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8LLSbuZuNFy0"
      },
      "outputs": [],
      "source": [
        "def getPerformanceOfLast3Matches(data):\n",
        "    HM1 = []    # result of the last match of home team\n",
        "    AM1 = []    # result of the last match of away team\n",
        "\n",
        "    HM2 = []    # result of the 2nd last match of home team\n",
        "    AM2 = []\n",
        "\n",
        "    HM3 = []    # result of the 3rd last match of home team\n",
        "    AM3 = []\n",
        "\n",
        "    teams = {}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None])  #[3rd, 2nd, latest data]\n",
        "\n",
        "        HM3.append(teams[data.iloc[i].HomeTeam].popleft())\n",
        "        AM3.append(teams[data.iloc[i].AwayTeam].popleft())\n",
        "        HM2.append(teams[data.iloc[i].HomeTeam][0])\n",
        "        AM2.append(teams[data.iloc[i].AwayTeam][0])\n",
        "        HM1.append(teams[data.iloc[i].HomeTeam][1])\n",
        "        AM1.append(teams[data.iloc[i].AwayTeam][1])\n",
        "\n",
        "        if data.iloc[i].FTR == 'H':\n",
        "            # 主场 赢，则主场记为赢，客场记为输\n",
        "            teams[data.iloc[i].HomeTeam].append('W')\n",
        "            teams[data.iloc[i].AwayTeam].append('L')\n",
        "        elif data.iloc[i].FTR == 'A':\n",
        "            # 客场 赢，则主场记为输，客场记为赢\n",
        "            teams[data.iloc[i].AwayTeam].append('W')\n",
        "            teams[data.iloc[i].HomeTeam].append('L')\n",
        "        else:\n",
        "            # 平局\n",
        "            teams[data.iloc[i].AwayTeam].append('D')\n",
        "            teams[data.iloc[i].HomeTeam].append('D')\n",
        "\n",
        "    data.loc[:,'HM1'] = HM1\n",
        "    data.loc[:,'AM1'] = AM1\n",
        "    data.loc[:,'HM2'] = HM2\n",
        "    data.loc[:,'AM2'] = AM2\n",
        "    data.loc[:,'HM3'] = HM3\n",
        "    data.loc[:,'AM3'] = AM3\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TdUKOAbQNFy2"
      },
      "outputs": [],
      "source": [
        "##### 3.2.6 Derive features and remove invalid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "colab_type": "code",
        "id": "11TdoTEXNFy3",
        "outputId": "53d1a6b3-f486-4988-9454-19c831f251a0"
      },
      "outputs": [],
      "source": [
        "getCumulativeGoalsDiff(training_data)   # FTHG, FTAG -> HCGD, ACGD\n",
        "getAverageShotsOnGoalInPast3Matches(training_data)  # HS, AS -> HAHS, AAHS\n",
        "getDeltaTime(training_data)     # Date -> HDT, ADT\n",
        "getDistance(training_data,geometricData)    # HomeTeam, AwayTeam -> DIS\n",
        "getPerformanceOfLast3Matches(training_data) # FTR -> HM1,AM1, HM2,AM2, HM3,AM3 [latest,2nd,3rd]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "colab_type": "code",
        "id": "qrcvsiV8NFy5",
        "outputId": "6633583a-8631-4f1d-ff70-13721e580162"
      },
      "outputs": [],
      "source": [
        "training_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lhm0Tlr4NFy6"
      },
      "outputs": [],
      "source": [
        "Now a few rows contain NaN values due to the lack of data in the begining of each year, we need to remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "colab_type": "code",
        "id": "O4xJxb9oNFy7",
        "outputId": "cf936671-dbe1-4edd-f288-d4946832e0db"
      },
      "outputs": [],
      "source": [
        "training_data = removeInvalidData(training_data)\n",
        "training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFBcPsCw41qB"
      },
      "outputs": [],
      "source": [
        "### 3.3 Second Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzQaonD-NFy_"
      },
      "outputs": [],
      "source": [
        "##### 3.3.1 Drop intermediate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "EseJt2_CNFzA",
        "outputId": "b87d5844-56a3-4515-e53a-8ef9141a83e6"
      },
      "outputs": [],
      "source": [
        "dropedAttributes = selectedAttributes.copy()\n",
        "dropedAttributes.remove(\"HR\")\n",
        "dropedAttributes.remove(\"AR\")\n",
        "data = training_data.drop(dropedAttributes,1)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cloP9Sq1NFzC"
      },
      "outputs": [],
      "source": [
        "##### 3.3.2 Numerical data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5pOPFMpfNFzD"
      },
      "outputs": [],
      "source": [
        "numList = ['HR', 'AR', 'HCGD', 'ACGD', 'HAHS', 'AAHS', 'HDT', 'ADT', 'DIS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sfq9DSoGNFzE"
      },
      "outputs": [],
      "source": [
        "We first print out the statistics of each numerical feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "bBkQH3HuNFzF",
        "outputId": "f9061f2e-1640-4838-b0e0-891be896600e"
      },
      "outputs": [],
      "source": [
        "for col in numList:\n",
        "    l = data[col].tolist() \n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [size: {}]\".format(col,len(l)))\n",
        "    print(\"-\"*40)\n",
        "    print(\"min: {:.4f} \\nmax: {:.4f} \\nmedian:{:.4f}\".format(np.min(l),np.max(l),np.median(l)))\n",
        "    print(\"mean: {:.4f} \\nvariance: {:.4f} \\nstandard deviation: {:.4f}\".format(np.mean(l),np.var(l), np.std(l, ddof=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rjc_jrUkNFzH"
      },
      "outputs": [],
      "source": [
        "From the result, we can draw such conclusions:\n",
        "- HR & AR: The range is very small (2). From the median, the mean and also the small variance we can know that most values are 0 (as these two features are discrete) while value=2 is of low occurance.\n",
        "\n",
        "- HCGD & ACGD: Large range (>130) with negative values involved. The median and the mean demonstrates that there is a relatively greater number of negative values within the data set.\n",
        "\n",
        "- HAHS & AAHS: Moderate range (around 25) with all positive values. The median and the mean is at the half of the range while the variance is reasonable.\n",
        "\n",
        "- HDT & ADT: Similar moderate range (around 25) and variance with the above pair of data. But the median and the mean is at the one third of the range. Outliers may exist.\n",
        "\n",
        "- DIS: Large range (>450) with all positive values. Reasonable median and mean. But from the variance we can know that the values fluctruates significantly.\n",
        "\n",
        "- Comparing to the other features, the values of HR & AR are too small while that of DIS too large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EkthKF7J4eiU"
      },
      "outputs": [],
      "source": [
        "### 3.4 Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WfVvRgLjNFzI"
      },
      "outputs": [],
      "source": [
        "Separate the training data into feature set and label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "colab_type": "code",
        "id": "m5FejG8HNFzI",
        "outputId": "61f6cb29-3a57-4b5e-b745-6dcdfa9764f0"
      },
      "outputs": [],
      "source": [
        "X_all = data.copy()\n",
        "y_all = training_data['FTR']\n",
        "y_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GjrsbBkPNFzM"
      },
      "outputs": [],
      "source": [
        "##### 3.4.1 Rescale and standardize numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1ArXnrHWNFzM"
      },
      "outputs": [],
      "source": [
        "# z-score standardization\n",
        "stdScaler = StandardScaler().fit(X_all[numList])\n",
        "X_all[numList] = stdScaler.transform(X_all[numList])\n",
        "\n",
        "# min-max scaling\n",
        "minmaxScaler = preprocessing.MinMaxScaler().fit(X_all[numList])\n",
        "X_all[numList] = minmaxScaler.transform(X_all[numList])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "4WFmh6y2NFzO",
        "outputId": "010ad0a6-9c14-42ba-c416-b1d2791e30e7"
      },
      "outputs": [],
      "source": [
        "X_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtIOScthNFzP"
      },
      "outputs": [],
      "source": [
        "##### 3.4.2 Transform categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "colab_type": "code",
        "id": "_LTIBQl6NFzP",
        "outputId": "e70403cc-fa76-459b-acf9-e258e08b84df"
      },
      "outputs": [],
      "source": [
        "categList = [\"HM1\",\"AM1\", \"HM2\",\"AM2\", \"HM3\",\"AM3\"]\n",
        "\n",
        "# transform categorical features\n",
        "def transformCategoricalFeature(data,categoricalFeatureNames):\n",
        "    # transform feature to string\n",
        "    for col in categoricalFeatureNames:\n",
        "        data[col] = data[col].astype('str')\n",
        "    \n",
        "    output = pd.DataFrame(index=data.index)\n",
        "\n",
        "    for col_name, col_data in data.iteritems():\n",
        "        if col_data.dtype == 'object':\n",
        "            col_data = pd.get_dummies(col_data, prefix = col_name)\n",
        "        output = output.join(col_data)\n",
        "    \n",
        "    return output\n",
        "X_all = transformCategoricalFeature(X_all, categList)\n",
        "X_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQchbTR5y393"
      },
      "outputs": [],
      "source": [
        "# 4. Methodology Overview [*Yanke*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "colab_type": "code",
        "id": "RkErqjSmWvEx",
        "outputId": "11b6d7cf-b927-4dd2-ff9d-e59c8b749402"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Split data set\n",
        "rule = {'H':1, 'A':0, 'D':2}\n",
        "y_all=y_all.map(rule)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,test_size = 0.3,random_state = 2,stratify = y_all)\n",
        "print(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "km3zSKnzDaMF"
      },
      "outputs": [],
      "source": [
        "#remove warning to see clear result\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "colab_type": "code",
        "id": "XshpHM1yuR17",
        "outputId": "fbe16945-c1a2-4545-feea-601de54f3e6b"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Naive Bayes\n",
        "gaussian =GaussianNB()\n",
        "gaussian.fit(X_train, y_train)\n",
        "y_gaussian = gaussian.predict(X_test)\n",
        "accuracy1 = accuracy_score(y_test, y_gaussian)\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "lr = LogisticRegression(solver='lbfgs', multi_class = 'multinomial') # Must specify solver and multi_class to reduce warning\n",
        "lr.fit(X_train, y_train)\n",
        "y_lr = lr.predict(X_test)\n",
        "accuracy2 = accuracy_score(y_test, y_lr)\n",
        "\n",
        "\n",
        "#Linear Discriminant Analysis\n",
        "lda =LDA()\n",
        "lda.fit(X_train, y_train)\n",
        "y_lda = lda.predict(X_test)\n",
        "accuracy3 = accuracy_score(y_test, y_lda)\n",
        "\n",
        "#Quadratic Discriminant Analysis\n",
        "qda =QDA()\n",
        "qda.fit(X_train, y_train)\n",
        "y_qda = qda.predict(X_test)\n",
        "accuracy4 = accuracy_score(y_test, y_qda)\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "dtc =DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "y_dtc = dtc.predict(X_test)\n",
        "accuracy5 = accuracy_score(y_test, y_dtc)\n",
        "\n",
        "\n",
        "#Multilayer Perceptron, a feedforward artificial Neural Net work model\n",
        "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(15,), random_state=1)\n",
        "nn.fit(X_train, y_train)\n",
        "y_nn = nn.predict(X_test)\n",
        "accuracy6 = accuracy_score(y_test, y_nn)\n",
        "\n",
        "print(\"{:<38}{}\".format('Gaussian Naive Bayes:',accuracy1))\n",
        "print(\"{:<38}{}\".format('Logistic Regression:',accuracy2))\n",
        "print(\"{:<38}{}\".format('Linear Discriminant Analysis:',accuracy3))\n",
        "print(\"{:<38}{}\".format('Quadratic Discriminant Analysis:',accuracy4))\n",
        "print(\"{:<38}{}\".format('Decision Tree:',accuracy5))\n",
        "print(\"{:<38}{}\".format('Multilayer Perceptron(Neural Network):',accuracy6))\n",
        "result=[accuracy1,accuracy2, accuracy3, accuracy4, accuracy5,accuracy6]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tbkatvtEpMz2"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from sklearn.metrics import f1_score\n",
        "# train classifier\n",
        "def train_classifier(clf, X_train, y_train):\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    print(\"time for training: {:.4f} sec\".format(end - start))\n",
        "\n",
        "# predict using the classifier\n",
        "def predict_labels(clf, features, target):\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    end = time()\n",
        "    print(\"time for prediction: {:.4f} sec\".format(end - start))\n",
        "    return f1_score(target, y_pred, pos_label=1, average=\"weighted\"), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "# print out the performance of each classifer\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    print(\"Classifier: {} [sample size: {}]\".format(clf.__class__.__name__, len(X_train)))\n",
        "\n",
        "    train_classifier(clf, X_train, y_train)\n",
        "\n",
        "    # evaluate model on train set\n",
        "    print(\"[on train set]\")\n",
        "    f1a, acc = predict_labels(clf, X_train, y_train)\n",
        "    print(\"F1 score: {:.4f} \".format(f1a))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "\n",
        "    # evaluate model on test set\n",
        "    print(\"[on test set]\")\n",
        "    f1b, acc = predict_labels(clf, X_test, y_test)\n",
        "    print(\"F1 score: {:.4f} \".format(f1b))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "    print(\"average F1: {:.4f}\".format((f1a+f1b)/2))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "goFY5n3gr_RX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "# adjust the hyperparameter of the model with best f1_score using grid search  \n",
        "def adjustClassifier(clf, f1_scorer, param, X_train, y_train):\n",
        "\n",
        "    grid_obj = GridSearchCV(clf,scoring=f1_scorer,param_grid=param,cv=5)\n",
        "    grid_obj = grid_obj.fit(X_train,y_train)\n",
        "\n",
        "    clf = grid_obj.best_estimator_\n",
        "\n",
        "    return clf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lF808gbxt-He"
      },
      "outputs": [],
      "source": [
        "#cross-validation with KFold\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "colab_type": "code",
        "id": "YvTglElnvUWo",
        "outputId": "494cc6d8-fcee-4235-f1a6-cfb8f29ce1da"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "#Logistic Regression\n",
        "#Score Before optimization\n",
        "print('Before optimization')\n",
        "clf2 = LogisticRegression(solver='lbfgs', multi_class = 'multinomial')\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Score after optimization\n",
        "print('After Optimization')\n",
        "clf = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial')\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')   #f1-scorer, need to set average to 'weighted' since target is multi class\n",
        "# set hyper parameter to be optimised\n",
        "parameters = { \n",
        "              'C' :[1.0, 100.0, 1000.0],\n",
        "              'max_iter':[100,200,300, 400, 500],\n",
        "              'intercept_scaling':[0.1, 0.5, 1.0]\n",
        "             }\n",
        "lr_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lr_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lr_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "colab_type": "code",
        "id": "ndS_RCfD0wf_",
        "outputId": "61eaf630-f8bb-4598-c487-4e608994230e"
      },
      "outputs": [],
      "source": [
        "# GaussianNB\n",
        "print('Before optimization')\n",
        "clf2 = GaussianNB()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "clf = GaussianNB()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "parameters = { \n",
        "              'var_smoothing': [1e-09, 1e-07, 1e-05, 1e-11, 1e-13]\n",
        "             }\n",
        "gaussian_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(gaussian_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(gaussian_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "jXL0cBfF14DR",
        "outputId": "6d7305df-54b2-4827-a3dc-76a4a6699632"
      },
      "outputs": [],
      "source": [
        "#LDA\n",
        "print('Before optimization')\n",
        "clf2 = LDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'tol': [ 0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = LDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper paramete\n",
        "lda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lda_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "2jwNxO8j3g-O",
        "outputId": "861e59ba-5029-408c-8139-87ae6cfc1cc0"
      },
      "outputs": [],
      "source": [
        "#QDA()\n",
        "print('Before optimization')\n",
        "clf2 = QDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'reg_param': [0, 0.1, 0.01, 0.001],\n",
        "              'tol': [0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = QDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "qda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(qda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(qda_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "colab_type": "code",
        "id": "4uEQloCe4jOr",
        "outputId": "808a5bc6-f06e-4576-8f6c-265ebac8708a"
      },
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "print('Before optimization')\n",
        "clf2 = DecisionTreeClassifier()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "                'min_impurity_decrease':[0, 0.1, 1]\n",
        "             }\n",
        "clf = DecisionTreeClassifier()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "dtc_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(dtc_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(dtc_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8ehaLX_Wc-_d"
      },
      "outputs": [],
      "source": [
        "#MLP Classifier cannot be directly used as a base estimator in Ada Boosting estimator(sample_weight not available)\n",
        "#so this custom classifier will fix this problem\n",
        "#This can be found at: https://stackoverflow.com/questions/55632010/using-scikit-learns-mlpclassifier-in-adaboostclassifier\n",
        "class customMLPClassifier(MLPClassifier):\n",
        "    def resample_with_replacement(self, X_train, y_train, sample_weight):\n",
        "\n",
        "        # normalize sample_weights if not already\n",
        "        sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
        "\n",
        "        X_train_resampled = np.zeros((len(X_train), len(X_train[0])), dtype=np.float32)\n",
        "        y_train_resampled = np.zeros((len(y_train)), dtype=np.int)\n",
        "        for i in range(len(X_train)):\n",
        "            # draw a number from 0 to len(X_train)-1\n",
        "            draw = np.random.choice(np.arange(len(X_train)), p=sample_weight)\n",
        "\n",
        "            # place the X and y at the drawn number into the resampled X and y\n",
        "            X_train_resampled[i] = X_train[draw]\n",
        "            y_train_resampled[i] = y_train[draw]\n",
        "\n",
        "        return X_train_resampled, y_train_resampled\n",
        "\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        if sample_weight is not None:\n",
        "            X, y = self.resample_with_replacement(X, y, sample_weight)\n",
        "\n",
        "        return self._fit(X, y, incremental=(self.warm_start and\n",
        "                                            hasattr(self, \"classes_\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "colab_type": "code",
        "id": "bdajc1Hu6q8K",
        "outputId": "413c6646-eb67-4997-b619-065fc13a467e"
      },
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "\n",
        "print('Before optimization')\n",
        "clf2 = customMLPClassifer()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'alpha': [ 1e-03, 1e-05, 1e-07],\n",
        "              'hidden_layer_sizes':[ (5,), (10,), (15,)],\n",
        "              'learning_rate_init':[0.01, 0.001, 0.0001],\n",
        "             }\n",
        "clf = customMLPClassifer()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "nn_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(nn_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(nn_2, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "rWa8ykF6EXgC",
        "outputId": "f293eceb-c4c8-4ef7-c067-09e5cf7c4531"
      },
      "outputs": [],
      "source": [
        "#accuracy result after optimization\n",
        "#compare with previous result\n",
        "print(\"{:<32}{:20}{:20}\".format(\"classifier\", \"before\",\"after\" ))\n",
        "estimators = [lr_2, gaussian_2, lda_2, qda_2, dtc_2, nn_2]\n",
        "for i in range(0,len(estimators)):\n",
        "  estimators[i].fit(X_train, y_train)\n",
        "  y = estimators[i].predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y)\n",
        "  print(\"{:<32}{:<20}{:<20}\".format(estimators[i].__class__.__name__+':', result[i], accuracy ))\n",
        "\n",
        "#we can see that most classifier has slightly better performance after hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "colab_type": "code",
        "id": "DpZTT6dZ4bo6",
        "outputId": "6ef80e48-d0a0-4a94-fc00-5dc38a880333"
      },
      "outputs": [],
      "source": [
        "#Ensemble model use Ada boosting method\n",
        "#LDA and QDA cannot be used as base_estimator of ada boosting in scikit-learn, so we cannot ensemble these 2 estimators\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model1 = [lr_2, gaussian_2, dtc_2]\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)\n",
        "for estimator in model1:\n",
        "  model_ada = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = estimator)\n",
        "  results_ada = model_selection.cross_val_score(model_ada,X_train, y_train, cv=kfold_ada)\n",
        "  print(results_ada.mean())\n",
        "  train_predict(model_ada, X_train, y_train, X_test, y_test)\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "# clf = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = nn_2)\n",
        "# results_ada = model_selection.cross_val_score(clf,X_train, y_train, cv=kfold_ada)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ymJSfT6yojFL"
      },
      "outputs": [],
      "source": [
        "#final model, this gives better cross_validation_score and f1_score for test set\n",
        "final_model = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = lr_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RicM6wtp1jlf"
      },
      "outputs": [],
      "source": [
        "# 5. Model Training & Validation [*Yanke*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h1cNAnlv1mVn"
      },
      "outputs": [],
      "source": [
        "# 6. Result [*Yi*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ev2RFUeQ1pT2"
      },
      "outputs": [],
      "source": [
        "# 7. Final Predictions on Test Set [*Yusi*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XUC5szgpNFzU"
      },
      "outputs": [],
      "source": []
    }
  ]
}