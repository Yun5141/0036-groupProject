{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FootballResultPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yun5141/comp0036/blob/master/FootballResultPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RbwPTMh0lmA6"
      },
      "source": [
        "# 1. Introduction [*Terry*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lNNXxH5mSMN"
      },
      "source": [
        "# 2. Data Import  [*Yun*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kND_qBXNFx1",
        "colab_type": "text"
      },
      "source": [
        "We first import all the packages that will be used in the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1q0F9DFNFx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "#!pip3 install geopy\n",
        "from geopy.distance import geodesic \n",
        "from geopy.distance import great_circle \n",
        "\n",
        "#!pip3 install sklearn\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGAQYyhMNFx5",
        "colab_type": "text"
      },
      "source": [
        "And then the data sets from our github repository (https://github.com/Yun5141/comp0036):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB6sgvUmNFx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data set\n",
        "url=\"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-training.csv\"\n",
        "raw_training_data=pd.read_csv(url)\n",
        "\n",
        "# test set\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-test.csv'\n",
        "rawData_toPred = pd.read_csv(url)\n",
        "\n",
        "# 2019 up-to-date data (from http://www.football-data.co.uk)\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl2019.csv'\n",
        "rawData_2019_uptodate = pd.read_csv(url)\n",
        "\n",
        "# geometric information of teams\n",
        "# to calculate the distance needed to travel for the away team\n",
        "url = \"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/stadiums-with-GPS-coordinates.csv\"\n",
        "geometricData = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tnNgP1TpsS-c"
      },
      "source": [
        "# 3. Data Transformation & Exploration [*Yun*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7B_FaFS_38OD"
      },
      "source": [
        "### 3.1 Initial Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYo2F4b0NFx-",
        "colab_type": "text"
      },
      "source": [
        "We first visualize the raw training data and find that:\n",
        "- The shape of the dataframe is 4180 rows x 73 columns, but some columns are empty and unamed.\n",
        "- There are two different date formats, \"%d/%m/%y\" and \"%d/%m/%Y\".\n",
        "- The involved data is from 2008-08-16 to 2019-05-12 (i.e. there are totally 11 seasons)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23hh57O8NFx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "bc0f2713-edaa-42c0-f4ef-69fdbca68a10"
      },
      "source": [
        "raw_training_data"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>FTR</th>\n",
              "      <th>HTHG</th>\n",
              "      <th>HTAG</th>\n",
              "      <th>HTR</th>\n",
              "      <th>Referee</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HST</th>\n",
              "      <th>AST</th>\n",
              "      <th>HF</th>\n",
              "      <th>AF</th>\n",
              "      <th>HC</th>\n",
              "      <th>AC</th>\n",
              "      <th>HY</th>\n",
              "      <th>AY</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>Unnamed: 22</th>\n",
              "      <th>Unnamed: 23</th>\n",
              "      <th>Unnamed: 24</th>\n",
              "      <th>Unnamed: 25</th>\n",
              "      <th>Unnamed: 26</th>\n",
              "      <th>Unnamed: 27</th>\n",
              "      <th>Unnamed: 28</th>\n",
              "      <th>Unnamed: 29</th>\n",
              "      <th>Unnamed: 30</th>\n",
              "      <th>Unnamed: 31</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "      <th>Unnamed: 33</th>\n",
              "      <th>Unnamed: 34</th>\n",
              "      <th>Unnamed: 35</th>\n",
              "      <th>Unnamed: 36</th>\n",
              "      <th>Unnamed: 37</th>\n",
              "      <th>Unnamed: 38</th>\n",
              "      <th>Unnamed: 39</th>\n",
              "      <th>Unnamed: 40</th>\n",
              "      <th>Unnamed: 41</th>\n",
              "      <th>Unnamed: 42</th>\n",
              "      <th>Unnamed: 43</th>\n",
              "      <th>Unnamed: 44</th>\n",
              "      <th>Unnamed: 45</th>\n",
              "      <th>Unnamed: 46</th>\n",
              "      <th>Unnamed: 47</th>\n",
              "      <th>Unnamed: 48</th>\n",
              "      <th>Unnamed: 49</th>\n",
              "      <th>Unnamed: 50</th>\n",
              "      <th>Unnamed: 51</th>\n",
              "      <th>Unnamed: 52</th>\n",
              "      <th>Unnamed: 53</th>\n",
              "      <th>Unnamed: 54</th>\n",
              "      <th>Unnamed: 55</th>\n",
              "      <th>Unnamed: 56</th>\n",
              "      <th>Unnamed: 57</th>\n",
              "      <th>Unnamed: 58</th>\n",
              "      <th>Unnamed: 59</th>\n",
              "      <th>Unnamed: 60</th>\n",
              "      <th>Unnamed: 61</th>\n",
              "      <th>Unnamed: 62</th>\n",
              "      <th>Unnamed: 63</th>\n",
              "      <th>Unnamed: 64</th>\n",
              "      <th>Unnamed: 65</th>\n",
              "      <th>Unnamed: 66</th>\n",
              "      <th>Unnamed: 67</th>\n",
              "      <th>Unnamed: 68</th>\n",
              "      <th>Unnamed: 69</th>\n",
              "      <th>Unnamed: 70</th>\n",
              "      <th>Unnamed: 71</th>\n",
              "      <th>Unnamed: 72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>West Brom</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>H Webb</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>Stoke</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>C Foy</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>A Marriner</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Hull</td>\n",
              "      <td>Fulham</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>P Walton</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Middlesbrough</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>M Atkinson</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>M Atkinson</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>J Moss</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>Huddersfield</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>L Probert</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Everton</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>A Marriner</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Watford</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>C Kavanagh</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4180 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date       HomeTeam  ... Unnamed: 71  Unnamed: 72\n",
              "0       16/08/08        Arsenal  ...         NaN          NaN\n",
              "1       16/08/08         Bolton  ...         NaN          NaN\n",
              "2       16/08/08        Everton  ...         NaN          NaN\n",
              "3       16/08/08           Hull  ...         NaN          NaN\n",
              "4       16/08/08  Middlesbrough  ...         NaN          NaN\n",
              "...          ...            ...  ...         ...          ...\n",
              "4175  12/05/2019      Liverpool  ...         NaN          NaN\n",
              "4176  12/05/2019     Man United  ...         NaN          NaN\n",
              "4177  12/05/2019    Southampton  ...         NaN          NaN\n",
              "4178  12/05/2019      Tottenham  ...         NaN          NaN\n",
              "4179  12/05/2019        Watford  ...         NaN          NaN\n",
              "\n",
              "[4180 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087tcJQoNFyE",
        "colab_type": "text"
      },
      "source": [
        "We drop the unamed columns and find now the shape of the dataframe is 4180 rows x 22 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yny3d4baNFyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "6c5c7361-ca06-4296-eea6-24018bf96120"
      },
      "source": [
        "raw_training_data = raw_training_data[raw_training_data.columns[~raw_training_data.columns.str.contains('Unnamed:')]]\n",
        "raw_training_data"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>FTR</th>\n",
              "      <th>HTHG</th>\n",
              "      <th>HTAG</th>\n",
              "      <th>HTR</th>\n",
              "      <th>Referee</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HST</th>\n",
              "      <th>AST</th>\n",
              "      <th>HF</th>\n",
              "      <th>AF</th>\n",
              "      <th>HC</th>\n",
              "      <th>AC</th>\n",
              "      <th>HY</th>\n",
              "      <th>AY</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>West Brom</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>H Webb</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>Stoke</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>C Foy</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>A Marriner</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Hull</td>\n",
              "      <td>Fulham</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>P Walton</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16/08/08</td>\n",
              "      <td>Middlesbrough</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>M Atkinson</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>M Atkinson</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>J Moss</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>Huddersfield</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>L Probert</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Everton</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>A Marriner</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Watford</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>C Kavanagh</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4180 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date       HomeTeam      AwayTeam  FTHG  FTAG  ... AC  HY  AY HR AR\n",
              "0       16/08/08        Arsenal     West Brom     1     0  ...  5   0   0  0  0\n",
              "1       16/08/08         Bolton         Stoke     3     1  ...  3   1   2  0  0\n",
              "2       16/08/08        Everton     Blackburn     2     3  ...  5   2   2  0  0\n",
              "3       16/08/08           Hull        Fulham     2     1  ...  6   3   0  0  0\n",
              "4       16/08/08  Middlesbrough     Tottenham     2     1  ...  9   1   2  0  0\n",
              "...          ...            ...           ...   ...   ...  ... ..  ..  .. .. ..\n",
              "4175  12/05/2019      Liverpool        Wolves     2     0  ...  1   0   2  0  0\n",
              "4176  12/05/2019     Man United       Cardiff     0     2  ...  2   3   3  0  0\n",
              "4177  12/05/2019    Southampton  Huddersfield     1     1  ...  3   0   1  0  0\n",
              "4178  12/05/2019      Tottenham       Everton     2     2  ...  4   0   2  0  0\n",
              "4179  12/05/2019        Watford      West Ham     1     4  ...  2   1   0  1  0\n",
              "\n",
              "[4180 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro6RH3StNFyH",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1.1 Invalid data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dga6PjfrNFyI",
        "colab_type": "text"
      },
      "source": [
        "We then check if there are rows containing None, NaN, infinite or overflowed values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8VK3ZMyNFyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8fe2c56d-56b3-470d-a809-72176250599e"
      },
      "source": [
        "def removeInvalidData(data):\n",
        "\n",
        "    # remove data which contains None\n",
        "    data.dropna(axis=0, how='any',inplace=True)\n",
        "\n",
        "    # remove data which contains NaN, infinite or overflowed number \n",
        "    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    data = data[indices_to_keep]\n",
        "\n",
        "    return data\n",
        "\n",
        "assert raw_training_data.shape[0] == removeInvalidData(raw_training_data).shape[0]"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IZeNmgNNFyN",
        "colab_type": "text"
      },
      "source": [
        "The result indicates that there is no rows containing such values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnAXcCh5NFyN",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1.2 Number of matches per season"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtdrUKgLNFyO",
        "colab_type": "text"
      },
      "source": [
        "The training set is of huge amount. To help learning the data, we separate the data set by seasons (from August to May) to see how many matches there are in each year.\n",
        "\n",
        "Before splitting the data set, we need to unify the date format first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxGeEyQqNFyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e79b13bf-26f5-46cb-fc61-7227ab04d860"
      },
      "source": [
        "# unify the different date formats and convert the type from str to timestamp  \n",
        "def unifyDate(data):\n",
        "\n",
        "    if not isinstance(data.Date[0],str):\n",
        "        return\n",
        "\n",
        "    newDate = []\n",
        "    for _, matchInfo in data.iterrows():\n",
        "        if len(matchInfo.Date) == 8 :\n",
        "            newDate.append( pd.to_datetime(matchInfo.Date, format=\"%d/%m/%y\" ))\n",
        "        elif len(matchInfo.Date) == 10 :\n",
        "            newDate.append(  pd.to_datetime(matchInfo.Date, format=\"%d/%m/%Y\" ))\n",
        "    \n",
        "    data['Date'] = pd.Series(newDate).values\n",
        "\n",
        "# to see the number of matches each year (season)\n",
        "def separateData(data):\n",
        "    dataframe_collection = {}\n",
        "\n",
        "    for year in range(2008, 2019):\n",
        "        dataframe_collection[year] = data[(data.Date > dt.datetime(year,8,1,0,0) ) & (data.Date < dt.datetime(year+1, 6, 1,0,0))]\n",
        "\n",
        "    return dataframe_collection\n",
        "\n",
        "unifyDate(raw_training_data)\n",
        "collection = separateData(raw_training_data)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn89z46XNFyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1a80c3d7-062b-4f01-a9c0-d583dd68d2b3"
      },
      "source": [
        "for key in collection.keys():\n",
        "    print(\"{} [{} rows x {} columns]\".format(key,collection[key].shape[0],collection[key].shape[1]))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2008 [380 rows x 22 columns]\n",
            "2009 [380 rows x 22 columns]\n",
            "2010 [380 rows x 22 columns]\n",
            "2011 [380 rows x 22 columns]\n",
            "2012 [380 rows x 22 columns]\n",
            "2013 [380 rows x 22 columns]\n",
            "2014 [380 rows x 22 columns]\n",
            "2015 [380 rows x 22 columns]\n",
            "2016 [380 rows x 22 columns]\n",
            "2017 [380 rows x 22 columns]\n",
            "2018 [380 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG9OBuM5NFyS",
        "colab_type": "text"
      },
      "source": [
        "The result shows that the number of matches each season stays the same (380 matches per season)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zte3G2-BNFyT",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1.3 Percentage of match result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYl3kex0NFyT",
        "colab_type": "text"
      },
      "source": [
        "We compute the average percentage of each match result per season and also that over the 11 years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_5GpdkNFyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPercentageOfMatchResult(data, matchResult):\n",
        "\n",
        "    if matchResult not in ['H', 'A', 'D']:\n",
        "        raise Exception('The second argument should only take values within [“H”,“A”,“D”]')\n",
        "    \n",
        "    n_wins = len(data[data.FTR == matchResult])\n",
        "\n",
        "    return n_wins / data.shape[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93W0nqfNFyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c712009-490e-4e9d-8326-bb92875f9602"
      },
      "source": [
        "# the average percentage of each match result per season\n",
        "for key in collection.keys():\n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [{}]\".format(key,len(collection[key])))\n",
        "    print(\"-\"*40)\n",
        "    print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"H\")*100))\n",
        "    print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"A\")*100))\n",
        "    print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"D\")*100))\n",
        "\n",
        "# the average percentage over the 11 years\n",
        "print(\"\\n\" +\"=\"*40)\n",
        "print(\"Overall [{}]\".format(len(raw_training_data)))\n",
        "print(\"-\"*40)\n",
        "print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"H\")*100))\n",
        "print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"A\")*100))\n",
        "print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"D\")*100))\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "2008 [380]\n",
            "----------------------------------------\n",
            "home team wins: 45.526%\n",
            "away team wins: 28.947%\n",
            "draw: 25.526%\n",
            "\n",
            "========================================\n",
            "2009 [380]\n",
            "----------------------------------------\n",
            "home team wins: 50.789%\n",
            "away team wins: 23.947%\n",
            "draw: 25.263%\n",
            "\n",
            "========================================\n",
            "2010 [380]\n",
            "----------------------------------------\n",
            "home team wins: 47.105%\n",
            "away team wins: 23.684%\n",
            "draw: 29.211%\n",
            "\n",
            "========================================\n",
            "2011 [380]\n",
            "----------------------------------------\n",
            "home team wins: 45.000%\n",
            "away team wins: 30.526%\n",
            "draw: 24.474%\n",
            "\n",
            "========================================\n",
            "2012 [380]\n",
            "----------------------------------------\n",
            "home team wins: 43.684%\n",
            "away team wins: 27.895%\n",
            "draw: 28.421%\n",
            "\n",
            "========================================\n",
            "2013 [380]\n",
            "----------------------------------------\n",
            "home team wins: 47.105%\n",
            "away team wins: 32.368%\n",
            "draw: 20.526%\n",
            "\n",
            "========================================\n",
            "2014 [380]\n",
            "----------------------------------------\n",
            "home team wins: 45.263%\n",
            "away team wins: 30.263%\n",
            "draw: 24.474%\n",
            "\n",
            "========================================\n",
            "2015 [380]\n",
            "----------------------------------------\n",
            "home team wins: 41.316%\n",
            "away team wins: 30.526%\n",
            "draw: 28.158%\n",
            "\n",
            "========================================\n",
            "2016 [380]\n",
            "----------------------------------------\n",
            "home team wins: 49.211%\n",
            "away team wins: 28.684%\n",
            "draw: 22.105%\n",
            "\n",
            "========================================\n",
            "2017 [380]\n",
            "----------------------------------------\n",
            "home team wins: 45.526%\n",
            "away team wins: 28.421%\n",
            "draw: 26.053%\n",
            "\n",
            "========================================\n",
            "2018 [380]\n",
            "----------------------------------------\n",
            "home team wins: 47.632%\n",
            "away team wins: 33.684%\n",
            "draw: 18.684%\n",
            "\n",
            "========================================\n",
            "Overall [4180]\n",
            "----------------------------------------\n",
            "home team wins: 46.196%\n",
            "away team wins: 28.995%\n",
            "draw: 24.809%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43mHSTIoNFya",
        "colab_type": "text"
      },
      "source": [
        "From the result, we find that in all cases the result 'home team wins' is of the highest probability, and 'H':'A':'D' $\\approx$ 5:3:2 in general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRlWYgxKNFyb",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1.4 Relationship between attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py97gHJvNFyc",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at the attributes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R13hg3GNFyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7d05551c-0689-4086-dcac-74600f85960d"
      },
      "source": [
        "raw_training_data.columns"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
              "       'HTR', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
              "       'HY', 'AY', 'HR', 'AR'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGF1QVGFNFyf",
        "colab_type": "text"
      },
      "source": [
        "We can plot a Pearson Correlation Heatmap to see the top 10 features related to the match result 'FTR':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FTQvYUANFyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "8cb4aed0-ae38-4b59-a37a-eeb0b5fff978"
      },
      "source": [
        "# plot the top 10 features related to FTR\n",
        "def plotGraph(X_all, Y_all):\n",
        "\n",
        "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
        "\n",
        "    #FTR correlation matrix\n",
        "    plt.figure(figsize=(12,12))\n",
        "    k = 11 # number of variables for heatmap\n",
        "    cols = abs(train_data.astype(float).corr()).nlargest(k, 'FTR')['FTR'].index\n",
        "    cm = np.corrcoef(train_data[cols].values.T)\n",
        "    sns.set(font_scale=1.25)\n",
        "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 12}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "    plt.show()\n",
        "\n",
        "attributes = raw_training_data.drop(['Date','HomeTeam', 'AwayTeam', 'Referee','FTR'],1)\n",
        "attributes['HTR'] = attributes['HTR'].map({'H':1,'A':0,'D':2})\n",
        "label = raw_training_data['FTR']\n",
        "label = label.map({'H':1,'A':0,'D':2})\n",
        "plotGraph(attributes,label)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAKaCAYAAAD2/3vHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzRcDr60NFyi",
        "colab_type": "text"
      },
      "source": [
        "As shown in the graph, the top 10 features are HTR, FTHG, HTHG, HST, HS, HR, AS, AST, HTAG,FTAG (ordered from the greatest to least). \n",
        "\n",
        "It is notable that the goal scored at full time (FTXG) & goal scored at half time (HTXG) and the total number of shots on goal (XS) & that on target (XST) are the two pairs of data which is highly correlated (>0.65).\n",
        "\n",
        "So within the top 10 we pick the following attributes to create features:\n",
        "- FTHG, FTAG -> the cumulative full time goal difference by home team and away team\n",
        "- HS, AS -> the average number of shots on goal in the past 3 matches by home team and away team\n",
        "- HR, AR (as features directly)\n",
        "\n",
        "Additionally, we derive features by using:\n",
        "- Date -> the delta time from last match of home team and away team\n",
        "- HomeTeam, AwayTeam -> the distance needed to travel for the away team (with the help of extra data source)\n",
        "- FTR -> the performance of past 3 matches of the home team and away team\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--kHgA_HNFyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "584e5544-919a-4dad-fb7a-589c59019407"
      },
      "source": [
        "selectedAttributes = [\"Date\",\"HomeTeam\", \"AwayTeam\",\"FTR\",\"FTHG\",\"FTAG\",\"HS\",\"AS\",\"HR\",\"AR\"]\n",
        "training_data = raw_training_data[selectedAttributes]\n",
        "training_data"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>West Brom</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>Stoke</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Hull</td>\n",
              "      <td>Fulham</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Middlesbrough</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>Huddersfield</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Everton</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Watford</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4180 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date       HomeTeam      AwayTeam FTR  FTHG  FTAG  HS  AS  HR  AR\n",
              "0    2008-08-16        Arsenal     West Brom   H     1     0  24   5   0   0\n",
              "1    2008-08-16         Bolton         Stoke   H     3     1  14   8   0   0\n",
              "2    2008-08-16        Everton     Blackburn   A     2     3  10  15   0   0\n",
              "3    2008-08-16           Hull        Fulham   H     2     1  11  12   0   0\n",
              "4    2008-08-16  Middlesbrough     Tottenham   H     2     1  14   8   0   0\n",
              "...         ...            ...           ...  ..   ...   ...  ..  ..  ..  ..\n",
              "4175 2019-05-12      Liverpool        Wolves   H     2     0  13   7   0   0\n",
              "4176 2019-05-12     Man United       Cardiff   A     0     2  26  13   0   0\n",
              "4177 2019-05-12    Southampton  Huddersfield   D     1     1  10  10   0   0\n",
              "4178 2019-05-12      Tottenham       Everton   D     2     2  11  17   0   0\n",
              "4179 2019-05-12        Watford      West Ham   A     1     4  17  16   1   0\n",
              "\n",
              "[4180 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4bC5O7w4J16"
      },
      "source": [
        "### 3.2 Feature Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mjmXp8Y06enf"
      },
      "source": [
        "##### 3.2.1 Cumulative full time goal difference by home team and away team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMbyUF2CNFyl",
        "colab_type": "text"
      },
      "source": [
        "As we have found that the number of matches per season is always the same, we can simply use i % 380 == 0 to check if it is a new season and to initialize the goal difference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1APZ-dZ-NFym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the cumulative goal difference (before the current match) scored by home team and away team  \n",
        "def getCumulativeGoalsDiff(data):\n",
        "    teams = {}\n",
        "    HCGD = [] \n",
        "    ACGD = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []\n",
        "\n",
        "        FTHG = data.iloc[i]['FTHG']\n",
        "        FTAG = data.iloc[i]['FTAG']\n",
        "\n",
        "        try:\n",
        "            cgd_h = teams[data.iloc[i].HomeTeam].pop()\n",
        "            cgd_a = teams[data.iloc[i].AwayTeam].pop()\n",
        "        except:\n",
        "            cgd_h = 0\n",
        "            cgd_a = 0\n",
        "\n",
        "        HCGD.append(cgd_h)\n",
        "        ACGD.append(cgd_a)\n",
        "        cgd_h = cgd_h + FTHG - FTAG\n",
        "        teams[data.iloc[i].HomeTeam].append(cgd_h)\n",
        "        cgd_a = cgd_a + FTAG - FTHG\n",
        "        teams[data.iloc[i].AwayTeam].append(cgd_a)\n",
        "\n",
        "    data.loc[:,'HCGD'] = pd.Series(HCGD)\n",
        "    data.loc[:,'ACGD'] = pd.Series(ACGD)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAqg4IhANFyp",
        "colab_type": "text"
      },
      "source": [
        "##### 3.2.2 Average number of shots on goal in the past 3 matches by home team and away team"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNlS0UYXNFyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the average number of shots on goal in the past 3 matches by home team and away team  \n",
        "def getAverageShotsOnGoalInPast3Matches(data):\n",
        "    teams = {}\n",
        "    HAHS = [] \n",
        "    AAHS = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None]) #[3rd, 2nd, latest data]\n",
        "\n",
        "        try:\n",
        "            ahs_h = np.mean(teams[data.iloc[i].HomeTeam])\n",
        "            ahs_a = np.mean(teams[data.iloc[i].AwayTeam])\n",
        "        except:\n",
        "            ahs_h = None\n",
        "            ahs_a = None\n",
        "\n",
        "        HAHS.append(ahs_h)\n",
        "        AAHS.append(ahs_a)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].popleft()\n",
        "        teams[data.iloc[i].HomeTeam].append(data.iloc[i].HS)\n",
        "\n",
        "        teams[data.iloc[i].AwayTeam].popleft()\n",
        "        teams[data.iloc[i].AwayTeam].append(data.iloc[i].AS)\n",
        "\n",
        "    data.loc[:,'HAHS'] = pd.Series(HAHS)\n",
        "    data.loc[:,'AAHS'] = pd.Series(AAHS)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q-4CgM2T5-G2"
      },
      "source": [
        "##### 3.2.3 Delta time from last match for home team and away team  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMuBcp-jNFyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the delta time from last match for home team and away team  [done]\n",
        "def getDeltaTime(data):\n",
        "    \n",
        "    teams = {}\n",
        "\n",
        "    HDT = []\n",
        "    ADT = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []    # to store last match date\n",
        "\n",
        "        currentDate = data.iloc[i].Date\n",
        "\n",
        "        try:\n",
        "            homeLastMatchDate = teams[data.iloc[i].HomeTeam].pop()\n",
        "            awayLastMatchDate = teams[data.iloc[i].AwayTeam].pop()\n",
        "\n",
        "            hdt = (currentDate - homeLastMatchDate).days\n",
        "            adt = (currentDate - awayLastMatchDate).days\n",
        "        except:\n",
        "            homeLastMatchDate = currentDate\n",
        "            awayLastMatchDate = currentDate\n",
        "\n",
        "            hdt = None\n",
        "            adt = None\n",
        "\n",
        "        HDT.append(hdt)\n",
        "        ADT.append(adt)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].append(currentDate)\n",
        "        teams[data.iloc[i].AwayTeam].append(currentDate)\n",
        "\n",
        "    data.loc[:,'HDT'] = HDT\n",
        "    data.loc[:,'ADT'] = ADT\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rzi4aEb35g3a"
      },
      "source": [
        "##### 3.2.4 Distance needed to travel for the away team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUNgVlWzNFyw",
        "colab_type": "text"
      },
      "source": [
        "The *geometricData* is an extra data source providing the latitude and longitude of teams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjiPYvbNNFyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the distance needed to travel for the away team \n",
        "def getDistance(data, geometricData):\n",
        "  array = []\n",
        "  for x in data.iterrows():\n",
        "   \n",
        "    home_lat = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Latitude\n",
        "    home_long = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Longitude\n",
        "    home_location = (np.float32(home_lat), np.float32(home_long))\n",
        "    \n",
        "    away_lat = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Latitude\n",
        "   \n",
        "    away_long = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Longitude\n",
        "    away_location = (np.float32(away_lat), np.float32(away_long))\n",
        "    array.append(np.float32(geodesic(home_location, away_location).km))\n",
        "  \n",
        "  \n",
        "  DIS = pd.Series(array)\n",
        "  data.loc[:,'DIS'] = DIS\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8MHYpEE261SS"
      },
      "source": [
        "##### 3.2.5 Performances of last 3 matches of home team and away team"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LLSbuZuNFy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPerformanceOfLast3Matches(data):\n",
        "    HM1 = []    # result of the last match of home team\n",
        "    AM1 = []    # result of the last match of away team\n",
        "\n",
        "    HM2 = []    # result of the 2nd last match of home team\n",
        "    AM2 = []\n",
        "\n",
        "    HM3 = []    # result of the 3rd last match of home team\n",
        "    AM3 = []\n",
        "\n",
        "    teams = {}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None])  #[3rd, 2nd, latest data]\n",
        "\n",
        "        HM3.append(teams[data.iloc[i].HomeTeam].popleft())\n",
        "        AM3.append(teams[data.iloc[i].AwayTeam].popleft())\n",
        "        HM2.append(teams[data.iloc[i].HomeTeam][0])\n",
        "        AM2.append(teams[data.iloc[i].AwayTeam][0])\n",
        "        HM1.append(teams[data.iloc[i].HomeTeam][1])\n",
        "        AM1.append(teams[data.iloc[i].AwayTeam][1])\n",
        "\n",
        "        if data.iloc[i].FTR == 'H':\n",
        "            # 主场 赢，则主场记为赢，客场记为输\n",
        "            teams[data.iloc[i].HomeTeam].append('W')\n",
        "            teams[data.iloc[i].AwayTeam].append('L')\n",
        "        elif data.iloc[i].FTR == 'A':\n",
        "            # 客场 赢，则主场记为输，客场记为赢\n",
        "            teams[data.iloc[i].AwayTeam].append('W')\n",
        "            teams[data.iloc[i].HomeTeam].append('L')\n",
        "        else:\n",
        "            # 平局\n",
        "            teams[data.iloc[i].AwayTeam].append('D')\n",
        "            teams[data.iloc[i].HomeTeam].append('D')\n",
        "\n",
        "    data.loc[:,'HM1'] = HM1\n",
        "    data.loc[:,'AM1'] = AM1\n",
        "    data.loc[:,'HM2'] = HM2\n",
        "    data.loc[:,'AM2'] = AM2\n",
        "    data.loc[:,'HM3'] = HM3\n",
        "    data.loc[:,'AM3'] = AM3\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdUKOAbQNFy2",
        "colab_type": "text"
      },
      "source": [
        "##### 3.2.6 Derive features and remove invalid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11TdoTEXNFy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "53d1a6b3-f486-4988-9454-19c831f251a0"
      },
      "source": [
        "getCumulativeGoalsDiff(training_data)   # FTHG, FTAG -> HCGD, ACGD\n",
        "getAverageShotsOnGoalInPast3Matches(training_data)  # HS, AS -> HAHS, AAHS\n",
        "getDeltaTime(training_data)     # Date -> HDT, ADT\n",
        "getDistance(training_data,geometricData)    # HomeTeam, AwayTeam -> DIS\n",
        "getPerformanceOfLast3Matches(training_data) # FTR -> HM1,AM1, HM2,AM2, HM3,AM3 [latest,2nd,3rd]"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>HCGD</th>\n",
              "      <th>ACGD</th>\n",
              "      <th>HAHS</th>\n",
              "      <th>AAHS</th>\n",
              "      <th>HDT</th>\n",
              "      <th>ADT</th>\n",
              "      <th>DIS</th>\n",
              "      <th>HM1</th>\n",
              "      <th>AM1</th>\n",
              "      <th>HM2</th>\n",
              "      <th>AM2</th>\n",
              "      <th>HM3</th>\n",
              "      <th>AM3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>West Brom</td>\n",
              "      <td>H</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>165.772156</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>Stoke</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70.146103</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.151447</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Hull</td>\n",
              "      <td>Fulham</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>252.920654</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-08-16</td>\n",
              "      <td>Middlesbrough</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>339.932465</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>16.333333</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>108.891106</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>-37</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>12.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>229.968140</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>Huddersfield</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-20</td>\n",
              "      <td>-54</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>306.418793</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Everton</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>283.650818</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Watford</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>-6</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>33.253616</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4180 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date       HomeTeam      AwayTeam FTR  ...   HM2   AM2   HM3   AM3\n",
              "0    2008-08-16        Arsenal     West Brom   H  ...  None  None  None  None\n",
              "1    2008-08-16         Bolton         Stoke   H  ...  None  None  None  None\n",
              "2    2008-08-16        Everton     Blackburn   A  ...  None  None  None  None\n",
              "3    2008-08-16           Hull        Fulham   H  ...  None  None  None  None\n",
              "4    2008-08-16  Middlesbrough     Tottenham   H  ...  None  None  None  None\n",
              "...         ...            ...           ...  ..  ...   ...   ...   ...   ...\n",
              "4175 2019-05-12      Liverpool        Wolves   H  ...     W     W     W     W\n",
              "4176 2019-05-12     Man United       Cardiff   A  ...     D     L     L     L\n",
              "4177 2019-05-12    Southampton  Huddersfield   D  ...     D     L     D     L\n",
              "4178 2019-05-12      Tottenham       Everton   D  ...     L     D     W     W\n",
              "4179 2019-05-12        Watford      West Ham   A  ...     L     W     D     D\n",
              "\n",
              "[4180 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrcvsiV8NFy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "6633583a-8631-4f1d-ff70-13721e580162"
      },
      "source": [
        "training_data.isnull().sum()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date          0\n",
              "HomeTeam      0\n",
              "AwayTeam      0\n",
              "FTR           0\n",
              "FTHG          0\n",
              "FTAG          0\n",
              "HS            0\n",
              "AS            0\n",
              "HR            0\n",
              "AR            0\n",
              "HCGD          0\n",
              "ACGD          0\n",
              "HAHS        335\n",
              "AAHS        335\n",
              "HDT         111\n",
              "ADT         111\n",
              "DIS           0\n",
              "HM1         110\n",
              "AM1         110\n",
              "HM2         219\n",
              "AM2         221\n",
              "HM3         331\n",
              "AM3         329\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhm0Tlr4NFy6",
        "colab_type": "text"
      },
      "source": [
        "Now a few rows contain NaN values due to the lack of data in the begining of each year, we need to remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4xJxb9oNFy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "cf936671-dbe1-4edd-f288-d4946832e0db"
      },
      "source": [
        "training_data = removeInvalidData(training_data)\n",
        "training_data"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>HCGD</th>\n",
              "      <th>ACGD</th>\n",
              "      <th>HAHS</th>\n",
              "      <th>AAHS</th>\n",
              "      <th>HDT</th>\n",
              "      <th>ADT</th>\n",
              "      <th>DIS</th>\n",
              "      <th>HM1</th>\n",
              "      <th>AM1</th>\n",
              "      <th>HM2</th>\n",
              "      <th>AM2</th>\n",
              "      <th>HM3</th>\n",
              "      <th>AM3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2008-09-13</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>3</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>290.604156</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2008-09-13</td>\n",
              "      <td>Man City</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.333333</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>261.179108</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2008-09-13</td>\n",
              "      <td>Newcastle</td>\n",
              "      <td>Hull</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>159.281448</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2008-09-13</td>\n",
              "      <td>Portsmouth</td>\n",
              "      <td>Middlesbrough</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.333333</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>420.982727</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2008-09-13</td>\n",
              "      <td>West Brom</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.333333</td>\n",
              "      <td>9.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>175.303436</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>H</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>16.333333</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>108.891106</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Cardiff</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>-37</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>12.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>229.968140</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>Huddersfield</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-20</td>\n",
              "      <td>-54</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>306.418793</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Everton</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>283.650818</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>2019-05-12</td>\n",
              "      <td>Watford</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>-6</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>33.253616</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3845 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date     HomeTeam       AwayTeam FTR  FTHG  ...  AM1  HM2  AM2  HM3  AM3\n",
              "29   2008-09-13    Blackburn        Arsenal   A     0  ...    W    D    L    W    W\n",
              "32   2008-09-13     Man City        Chelsea   A     1  ...    D    W    W    L    W\n",
              "33   2008-09-13    Newcastle           Hull   A     1  ...    L    W    D    D    W\n",
              "34   2008-09-13   Portsmouth  Middlesbrough   H     2  ...    W    L    L    L    W\n",
              "35   2008-09-13    West Brom       West Ham   H     3  ...    W    L    L    L    W\n",
              "...         ...          ...            ...  ..   ...  ...  ...  ...  ...  ...  ...\n",
              "4175 2019-05-12    Liverpool         Wolves   H     2  ...    W    W    W    W    W\n",
              "4176 2019-05-12   Man United        Cardiff   A     0  ...    L    D    L    L    L\n",
              "4177 2019-05-12  Southampton   Huddersfield   D     1  ...    D    D    L    D    L\n",
              "4178 2019-05-12    Tottenham        Everton   D     2  ...    W    L    D    W    W\n",
              "4179 2019-05-12      Watford       West Ham   A     1  ...    W    L    W    D    D\n",
              "\n",
              "[3845 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFBcPsCw41qB"
      },
      "source": [
        "### 3.3 Second Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzQaonD-NFy_",
        "colab_type": "text"
      },
      "source": [
        "##### 3.3.1 Drop intermediate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EseJt2_CNFzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b87d5844-56a3-4515-e53a-8ef9141a83e6"
      },
      "source": [
        "dropedAttributes = selectedAttributes.copy()\n",
        "dropedAttributes.remove(\"HR\")\n",
        "dropedAttributes.remove(\"AR\")\n",
        "data = training_data.drop(dropedAttributes,1)\n",
        "data"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>HCGD</th>\n",
              "      <th>ACGD</th>\n",
              "      <th>HAHS</th>\n",
              "      <th>AAHS</th>\n",
              "      <th>HDT</th>\n",
              "      <th>ADT</th>\n",
              "      <th>DIS</th>\n",
              "      <th>HM1</th>\n",
              "      <th>AM1</th>\n",
              "      <th>HM2</th>\n",
              "      <th>AM2</th>\n",
              "      <th>HM3</th>\n",
              "      <th>AM3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>3</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>290.604156</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.333333</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>261.179108</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>159.281448</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.333333</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>420.982727</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.333333</td>\n",
              "      <td>9.666667</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>175.303436</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>16.333333</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>108.891106</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>-37</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>12.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>229.968140</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-20</td>\n",
              "      <td>-54</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>306.418793</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>283.650818</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>-6</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>33.253616</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3845 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      HR  AR  HCGD  ACGD       HAHS       AAHS  ...  HM1  AM1  HM2 AM2 HM3 AM3\n",
              "29     0   0    -2     3  13.000000  19.666667  ...    L    W    D   L   W   W\n",
              "32     0   1     4     5  12.000000  12.333333  ...    W    D    W   W   L   W\n",
              "33     1   0    -2    -4   8.333333   9.333333  ...    L    L    W   D   D   W\n",
              "34     0   0    -2     1  10.333333  14.666667  ...    W    W    L   L   L   W\n",
              "35     0   0    -2     1  10.333333   9.666667  ...    D    W    L   L   L   W\n",
              "...   ..  ..   ...   ...        ...        ...  ...  ...  ...  ...  ..  ..  ..\n",
              "4175   0   0    65     3  16.333333  13.666667  ...    W    W    W   W   W   W\n",
              "4176   0   0    13   -37  14.000000  12.666667  ...    D    L    D   L   L   L\n",
              "4177   0   0   -20   -54  13.666667   8.333333  ...    L    D    D   L   D   L\n",
              "4178   0   0    28     8  18.000000  19.000000  ...    L    W    L   D   W   W\n",
              "4179   1   0    -4    -6  13.333333  14.666667  ...    L    W    L   W   D   D\n",
              "\n",
              "[3845 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloP9Sq1NFzC",
        "colab_type": "text"
      },
      "source": [
        "##### 3.3.2 Numerical data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pOPFMpfNFzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numList = ['HR', 'AR', 'HCGD', 'ACGD', 'HAHS', 'AAHS', 'HDT', 'ADT', 'DIS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfq9DSoGNFzE",
        "colab_type": "text"
      },
      "source": [
        "We first print out the statistics of each numerical feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBkQH3HuNFzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9061f2e-1640-4838-b0e0-891be896600e"
      },
      "source": [
        "for col in numList:\n",
        "    l = data[col].tolist() \n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [size: {}]\".format(col,len(l)))\n",
        "    print(\"-\"*40)\n",
        "    print(\"min: {:.4f} \\nmax: {:.4f} \\nmedian:{:.4f}\".format(np.min(l),np.max(l),np.median(l)))\n",
        "    print(\"mean: {:.4f} \\nvariance: {:.4f} \\nstandard deviation: {:.4f}\".format(np.mean(l),np.var(l), np.std(l, ddof=1)))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "HR [size: 3845]\n",
            "----------------------------------------\n",
            "min: 0.0000 \n",
            "max: 2.0000 \n",
            "median:0.0000\n",
            "mean: 0.0583 \n",
            "variance: 0.0585 \n",
            "standard deviation: 0.2419\n",
            "\n",
            "========================================\n",
            "AR [size: 3845]\n",
            "----------------------------------------\n",
            "min: 0.0000 \n",
            "max: 2.0000 \n",
            "median:0.0000\n",
            "mean: 0.0887 \n",
            "variance: 0.0891 \n",
            "standard deviation: 0.2986\n",
            "\n",
            "========================================\n",
            "HCGD [size: 3845]\n",
            "----------------------------------------\n",
            "min: -54.0000 \n",
            "max: 76.0000 \n",
            "median:-2.0000\n",
            "mean: -0.1545 \n",
            "variance: 268.4770 \n",
            "standard deviation: 16.3874\n",
            "\n",
            "========================================\n",
            "ACGD [size: 3845]\n",
            "----------------------------------------\n",
            "min: -54.0000 \n",
            "max: 78.0000 \n",
            "median:-2.0000\n",
            "mean: 0.2195 \n",
            "variance: 266.7305 \n",
            "standard deviation: 16.3340\n",
            "\n",
            "========================================\n",
            "HAHS [size: 3845]\n",
            "----------------------------------------\n",
            "min: 3.3333 \n",
            "max: 27.0000 \n",
            "median:12.0000\n",
            "mean: 12.4158 \n",
            "variance: 12.0246 \n",
            "standard deviation: 3.4681\n",
            "\n",
            "========================================\n",
            "AAHS [size: 3845]\n",
            "----------------------------------------\n",
            "min: 3.6667 \n",
            "max: 28.6667 \n",
            "median:12.3333\n",
            "mean: 12.8305 \n",
            "variance: 12.3910 \n",
            "standard deviation: 3.5205\n",
            "\n",
            "========================================\n",
            "HDT [size: 3845]\n",
            "----------------------------------------\n",
            "min: 2.0000 \n",
            "max: 27.0000 \n",
            "median:7.0000\n",
            "mean: 7.4637 \n",
            "variance: 11.7795 \n",
            "standard deviation: 3.4326\n",
            "\n",
            "========================================\n",
            "ADT [size: 3845]\n",
            "----------------------------------------\n",
            "min: 2.0000 \n",
            "max: 22.0000 \n",
            "median:7.0000\n",
            "mean: 7.4780 \n",
            "variance: 11.9130 \n",
            "standard deviation: 3.4520\n",
            "\n",
            "========================================\n",
            "DIS [size: 3845]\n",
            "----------------------------------------\n",
            "min: 0.9710 \n",
            "max: 473.8653 \n",
            "median:179.0834\n",
            "mean: 187.5142 \n",
            "variance: 12289.0815 \n",
            "standard deviation: 110.8705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjc_jrUkNFzH",
        "colab_type": "text"
      },
      "source": [
        "From the result, we can draw such conclusions:\n",
        "- HR & AR: The range is very small (2). From the median, the mean and also the small variance we can know that most values are 0 (as these two features are discrete) while value=2 is of low occurance.\n",
        "\n",
        "- HCGD & ACGD: Large range (>130) with negative values involved. The median and the mean demonstrates that there is a relatively greater number of negative values within the data set.\n",
        "\n",
        "- HAHS & AAHS: Moderate range (around 25) with all positive values. The median and the mean is at the half of the range while the variance is reasonable.\n",
        "\n",
        "- HDT & ADT: Similar moderate range (around 25) and variance with the above pair of data. But the median and the mean is at the one third of the range. Outliers may exist.\n",
        "\n",
        "- DIS: Large range (>450) with all positive values. Reasonable median and mean. But from the variance we can know that the values fluctruates significantly.\n",
        "\n",
        "- Comparing to the other features, the values of HR & AR are too small while that of DIS too large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EkthKF7J4eiU"
      },
      "source": [
        "### 3.4 Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfVvRgLjNFzI",
        "colab_type": "text"
      },
      "source": [
        "Separate the training data into feature set and label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5FejG8HNFzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "61f6cb29-3a57-4b5e-b745-6dcdfa9764f0"
      },
      "source": [
        "X_all = data.copy()\n",
        "y_all = training_data['FTR']\n",
        "y_all"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29      A\n",
              "32      A\n",
              "33      A\n",
              "34      H\n",
              "35      H\n",
              "       ..\n",
              "4175    H\n",
              "4176    A\n",
              "4177    D\n",
              "4178    D\n",
              "4179    A\n",
              "Name: FTR, Length: 3845, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjrsbBkPNFzM",
        "colab_type": "text"
      },
      "source": [
        "##### 3.4.1 Rescale and standardize numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ArXnrHWNFzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z-score standardization\n",
        "stdScaler = StandardScaler().fit(X_all[numList])\n",
        "X_all[numList] = stdScaler.transform(X_all[numList])\n",
        "\n",
        "# min-max scaling\n",
        "minmaxScaler = preprocessing.MinMaxScaler().fit(X_all[numList])\n",
        "X_all[numList] = minmaxScaler.transform(X_all[numList])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WFmh6y2NFzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "010ad0a6-9c14-42ba-c416-b1d2791e30e7"
      },
      "source": [
        "X_all"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>HCGD</th>\n",
              "      <th>ACGD</th>\n",
              "      <th>HAHS</th>\n",
              "      <th>AAHS</th>\n",
              "      <th>HDT</th>\n",
              "      <th>ADT</th>\n",
              "      <th>DIS</th>\n",
              "      <th>HM1</th>\n",
              "      <th>AM1</th>\n",
              "      <th>HM2</th>\n",
              "      <th>AM2</th>\n",
              "      <th>HM3</th>\n",
              "      <th>AM3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.612469</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.446970</td>\n",
              "      <td>0.366197</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.550246</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.226667</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.334769</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.888173</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.368650</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.228212</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515385</td>\n",
              "      <td>0.128788</td>\n",
              "      <td>0.450704</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.484246</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.436620</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.645911</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.619718</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.597765</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.422535</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.068266</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3845 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       HR   AR      HCGD      ACGD      HAHS      AAHS  ...  HM1  AM1  HM2 AM2 HM3 AM3\n",
              "29    0.0  0.0  0.400000  0.431818  0.408451  0.640000  ...    L    W    D   L   W   W\n",
              "32    0.0  0.5  0.446154  0.446970  0.366197  0.346667  ...    W    D    W   W   L   W\n",
              "33    0.5  0.0  0.400000  0.378788  0.211268  0.226667  ...    L    L    W   D   D   W\n",
              "34    0.0  0.0  0.400000  0.416667  0.295775  0.440000  ...    W    W    L   L   L   W\n",
              "35    0.0  0.0  0.400000  0.416667  0.295775  0.240000  ...    D    W    L   L   L   W\n",
              "...   ...  ...       ...       ...       ...       ...  ...  ...  ...  ...  ..  ..  ..\n",
              "4175  0.0  0.0  0.915385  0.431818  0.549296  0.400000  ...    W    W    W   W   W   W\n",
              "4176  0.0  0.0  0.515385  0.128788  0.450704  0.360000  ...    D    L    D   L   L   L\n",
              "4177  0.0  0.0  0.261538  0.000000  0.436620  0.186667  ...    L    D    D   L   D   L\n",
              "4178  0.0  0.0  0.630769  0.469697  0.619718  0.613333  ...    L    W    L   D   W   W\n",
              "4179  0.5  0.0  0.384615  0.363636  0.422535  0.440000  ...    L    W    L   W   D   D\n",
              "\n",
              "[3845 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtIOScthNFzP",
        "colab_type": "text"
      },
      "source": [
        "##### 3.4.2 Transform categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LTIBQl6NFzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e70403cc-fa76-459b-acf9-e258e08b84df"
      },
      "source": [
        "categList = [\"HM1\",\"AM1\", \"HM2\",\"AM2\", \"HM3\",\"AM3\"]\n",
        "\n",
        "# transform categorical features\n",
        "def transformCategoricalFeature(data,categoricalFeatureNames):\n",
        "    # transform feature to string\n",
        "    for col in categoricalFeatureNames:\n",
        "        data[col] = data[col].astype('str')\n",
        "    \n",
        "    output = pd.DataFrame(index=data.index)\n",
        "\n",
        "    for col_name, col_data in data.iteritems():\n",
        "        if col_data.dtype == 'object':\n",
        "            col_data = pd.get_dummies(col_data, prefix = col_name)\n",
        "        output = output.join(col_data)\n",
        "    \n",
        "    return output\n",
        "X_all = transformCategoricalFeature(X_all, categList)\n",
        "X_all"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>HCGD</th>\n",
              "      <th>ACGD</th>\n",
              "      <th>HAHS</th>\n",
              "      <th>AAHS</th>\n",
              "      <th>HDT</th>\n",
              "      <th>ADT</th>\n",
              "      <th>DIS</th>\n",
              "      <th>HM1_D</th>\n",
              "      <th>HM1_L</th>\n",
              "      <th>HM1_W</th>\n",
              "      <th>AM1_D</th>\n",
              "      <th>AM1_L</th>\n",
              "      <th>AM1_W</th>\n",
              "      <th>HM2_D</th>\n",
              "      <th>HM2_L</th>\n",
              "      <th>HM2_W</th>\n",
              "      <th>AM2_D</th>\n",
              "      <th>AM2_L</th>\n",
              "      <th>AM2_W</th>\n",
              "      <th>HM3_D</th>\n",
              "      <th>HM3_L</th>\n",
              "      <th>HM3_W</th>\n",
              "      <th>AM3_D</th>\n",
              "      <th>AM3_L</th>\n",
              "      <th>AM3_W</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.612469</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.446970</td>\n",
              "      <td>0.366197</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.550246</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.226667</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.334769</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.888173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.368650</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.228212</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515385</td>\n",
              "      <td>0.128788</td>\n",
              "      <td>0.450704</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.484246</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.436620</td>\n",
              "      <td>0.186667</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.645911</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.619718</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.597765</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4179</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.422535</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.068266</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3845 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       HR   AR      HCGD      ACGD      HAHS  ...  HM3_L  HM3_W  AM3_D  AM3_L  AM3_W\n",
              "29    0.0  0.0  0.400000  0.431818  0.408451  ...      0      1      0      0      1\n",
              "32    0.0  0.5  0.446154  0.446970  0.366197  ...      1      0      0      0      1\n",
              "33    0.5  0.0  0.400000  0.378788  0.211268  ...      0      0      0      0      1\n",
              "34    0.0  0.0  0.400000  0.416667  0.295775  ...      1      0      0      0      1\n",
              "35    0.0  0.0  0.400000  0.416667  0.295775  ...      1      0      0      0      1\n",
              "...   ...  ...       ...       ...       ...  ...    ...    ...    ...    ...    ...\n",
              "4175  0.0  0.0  0.915385  0.431818  0.549296  ...      0      1      0      0      1\n",
              "4176  0.0  0.0  0.515385  0.128788  0.450704  ...      1      0      0      1      0\n",
              "4177  0.0  0.0  0.261538  0.000000  0.436620  ...      0      0      0      1      0\n",
              "4178  0.0  0.0  0.630769  0.469697  0.619718  ...      0      1      0      0      1\n",
              "4179  0.5  0.0  0.384615  0.363636  0.422535  ...      0      0      1      0      0\n",
              "\n",
              "[3845 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQchbTR5y393"
      },
      "source": [
        "# 4. Methodology Overview [*Yanke*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkErqjSmWvEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "11b6d7cf-b927-4dd2-ff9d-e59c8b749402"
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Split data set\n",
        "rule = {'H':1, 'A':0, 'D':2}\n",
        "y_all=y_all.map(rule)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,test_size = 0.3,random_state = 2,stratify = y_all)\n",
        "print(X_test, y_test)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       HR   AR      HCGD      ACGD      HAHS  ...  HM3_L  HM3_W  AM3_D  AM3_L  AM3_W\n",
            "2333  0.0  0.0  0.415385  0.431818  0.281690  ...      1      0      0      1      0\n",
            "613   0.0  0.0  0.238462  0.340909  0.225352  ...      1      0      1      0      0\n",
            "423   0.0  0.0  0.376923  0.416667  0.507042  ...      1      0      0      0      1\n",
            "811   0.5  0.0  0.407692  0.325758  0.281690  ...      0      0      0      0      1\n",
            "1866  0.0  0.5  0.207692  0.356061  0.338028  ...      0      1      0      1      0\n",
            "...   ...  ...       ...       ...       ...  ...    ...    ...    ...    ...    ...\n",
            "453   0.0  0.0  0.400000  0.378788  0.366197  ...      1      0      0      1      0\n",
            "981   0.0  0.5  0.592308  0.295455  0.563380  ...      0      1      0      1      0\n",
            "890   0.0  0.0  0.523077  0.416667  0.366197  ...      1      0      0      1      0\n",
            "369   0.0  0.0  0.261538  0.280303  0.338028  ...      0      0      0      1      0\n",
            "3461  0.0  0.0  0.361538  0.401515  0.464789  ...      1      0      0      0      1\n",
            "\n",
            "[1154 rows x 27 columns] 2333    0\n",
            "613     1\n",
            "423     1\n",
            "811     2\n",
            "1866    1\n",
            "       ..\n",
            "453     2\n",
            "981     1\n",
            "890     0\n",
            "369     1\n",
            "3461    0\n",
            "Name: FTR, Length: 1154, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km3zSKnzDaMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove warning to see clear result\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XshpHM1yuR17",
        "colab_type": "code",
        "outputId": "fbe16945-c1a2-4545-feea-601de54f3e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Naive Bayes\n",
        "gaussian =GaussianNB()\n",
        "gaussian.fit(X_train, y_train)\n",
        "y_gaussian = gaussian.predict(X_test)\n",
        "accuracy1 = accuracy_score(y_test, y_gaussian)\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "lr = LogisticRegression(solver='lbfgs', multi_class = 'multinomial') # Must specify solver and multi_class to reduce warning\n",
        "lr.fit(X_train, y_train)\n",
        "y_lr = lr.predict(X_test)\n",
        "accuracy2 = accuracy_score(y_test, y_lr)\n",
        "\n",
        "\n",
        "#Linear Discriminant Analysis\n",
        "lda =LDA()\n",
        "lda.fit(X_train, y_train)\n",
        "y_lda = lda.predict(X_test)\n",
        "accuracy3 = accuracy_score(y_test, y_lda)\n",
        "\n",
        "#Quadratic Discriminant Analysis\n",
        "qda =QDA()\n",
        "qda.fit(X_train, y_train)\n",
        "y_qda = qda.predict(X_test)\n",
        "accuracy4 = accuracy_score(y_test, y_qda)\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "dtc =DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "y_dtc = dtc.predict(X_test)\n",
        "accuracy5 = accuracy_score(y_test, y_dtc)\n",
        "\n",
        "\n",
        "#Multilayer Perceptron, a feedforward artificial Neural Net work model\n",
        "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(15,), random_state=1)\n",
        "nn.fit(X_train, y_train)\n",
        "y_nn = nn.predict(X_test)\n",
        "accuracy6 = accuracy_score(y_test, y_nn)\n",
        "\n",
        "print(\"{:<38}{}\".format('Gaussian Naive Bayes:',accuracy1))\n",
        "print(\"{:<38}{}\".format('Logistic Regression:',accuracy2))\n",
        "print(\"{:<38}{}\".format('Linear Discriminant Analysis:',accuracy3))\n",
        "print(\"{:<38}{}\".format('Quadratic Discriminant Analysis:',accuracy4))\n",
        "print(\"{:<38}{}\".format('Decision Tree:',accuracy5))\n",
        "print(\"{:<38}{}\".format('Multilayer Perceptron(Neural Network):',accuracy6))\n",
        "result=[accuracy1,accuracy2, accuracy3, accuracy4, accuracy5,accuracy6]"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Naive Bayes:                 0.511265164644714\n",
            "Logistic Regression:                  0.5407279029462738\n",
            "Linear Discriminant Analysis:         0.5424610051993067\n",
            "Quadratic Discriminant Analysis:      0.4358752166377816\n",
            "Decision Tree:                        0.4150779896013865\n",
            "Multilayer Perceptron(Neural Network):0.5268630849220104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbkatvtEpMz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from sklearn.metrics import f1_score\n",
        "# train classifier\n",
        "def train_classifier(clf, X_train, y_train):\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    print(\"time for training: {:.4f} sec\".format(end - start))\n",
        "\n",
        "# predict using the classifier\n",
        "def predict_labels(clf, features, target):\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    end = time()\n",
        "    print(\"time for prediction: {:.4f} sec\".format(end - start))\n",
        "    return f1_score(target, y_pred, pos_label=1, average=\"weighted\"), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "# print out the performance of each classifer\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    print(\"Classifier: {} [sample size: {}]\".format(clf.__class__.__name__, len(X_train)))\n",
        "\n",
        "    train_classifier(clf, X_train, y_train)\n",
        "\n",
        "    # evaluate model on train set\n",
        "    print(\"[on train set]\")\n",
        "    f1a, acc = predict_labels(clf, X_train, y_train)\n",
        "    print(\"F1 score: {:.4f} \".format(f1a))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "\n",
        "    # evaluate model on test set\n",
        "    print(\"[on test set]\")\n",
        "    f1b, acc = predict_labels(clf, X_test, y_test)\n",
        "    print(\"F1 score: {:.4f} \".format(f1b))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "    print(\"average F1: {:.4f}\".format((f1a+f1b)/2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goFY5n3gr_RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "# adjust the hyperparameter of the model with best f1_score using grid search  \n",
        "def adjustClassifier(clf, f1_scorer, param, X_train, y_train):\n",
        "\n",
        "    grid_obj = GridSearchCV(clf,scoring=f1_scorer,param_grid=param,cv=5)\n",
        "    grid_obj = grid_obj.fit(X_train,y_train)\n",
        "\n",
        "    clf = grid_obj.best_estimator_\n",
        "\n",
        "    return clf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF808gbxt-He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cross-validation with KFold\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvTglElnvUWo",
        "colab_type": "code",
        "outputId": "494cc6d8-fcee-4235-f1a6-cfb8f29ce1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "#Logistic Regression\n",
        "#Score Before optimization\n",
        "print('Before optimization')\n",
        "clf2 = LogisticRegression(solver='lbfgs', multi_class = 'multinomial')\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Score after optimization\n",
        "print('After Optimization')\n",
        "clf = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial')\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')   #f1-scorer, need to set average to 'weighted' since target is multi class\n",
        "# set hyper parameter to be optimised\n",
        "parameters = { \n",
        "              'C' :[1.0, 100.0, 1000.0],\n",
        "              'max_iter':[100,200,300, 400, 500],\n",
        "              'intercept_scaling':[0.1, 0.5, 1.0]\n",
        "             }\n",
        "lr_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lr_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lr_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.5362288310615446\n",
            "Classifier: LogisticRegression [sample size: 2691]\n",
            "time for training: 0.1168 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0010 sec\n",
            "F1 score: 0.4680 \n",
            "accuracy: 0.5444\n",
            "[on test set]\n",
            "time for prediction: 0.0008 sec\n",
            "F1 score: 0.4618 \n",
            "accuracy: 0.5407\n",
            "average F1: 0.4649\n",
            "\n",
            "\n",
            "After Optimization\n",
            "0.5369709486438111\n",
            "Classifier: LogisticRegression [sample size: 2691]\n",
            "time for training: 0.0980 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0011 sec\n",
            "F1 score: 0.4694 \n",
            "accuracy: 0.5437\n",
            "[on test set]\n",
            "time for prediction: 0.0007 sec\n",
            "F1 score: 0.4634 \n",
            "accuracy: 0.5407\n",
            "average F1: 0.4664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndS_RCfD0wf_",
        "colab_type": "code",
        "outputId": "61eaf630-f8bb-4598-c487-4e608994230e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# GaussianNB\n",
        "print('Before optimization')\n",
        "clf2 = GaussianNB()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "clf = GaussianNB()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "parameters = { \n",
        "              'var_smoothing': [1e-09, 1e-07, 1e-05, 1e-11, 1e-13]\n",
        "             }\n",
        "gaussian_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(gaussian_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(gaussian_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.5195112212584332\n",
            "Classifier: GaussianNB [sample size: 2691]\n",
            "time for training: 0.0021 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0019 sec\n",
            "F1 score: 0.4787 \n",
            "accuracy: 0.5277\n",
            "[on test set]\n",
            "time for prediction: 0.0010 sec\n",
            "F1 score: 0.4675 \n",
            "accuracy: 0.5113\n",
            "average F1: 0.4731\n",
            "\n",
            "\n",
            "After optimization\n",
            "0.5195112212584332\n",
            "Classifier: GaussianNB [sample size: 2691]\n",
            "time for training: 0.0023 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0020 sec\n",
            "F1 score: 0.4787 \n",
            "accuracy: 0.5277\n",
            "[on test set]\n",
            "time for prediction: 0.0013 sec\n",
            "F1 score: 0.4675 \n",
            "accuracy: 0.5113\n",
            "average F1: 0.4731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXL0cBfF14DR",
        "colab_type": "code",
        "outputId": "6d7305df-54b2-4827-a3dc-76a4a6699632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#LDA\n",
        "print('Before optimization')\n",
        "clf2 = LDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'tol': [ 0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = LDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper paramete\n",
        "lda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lda_2, X_train, y_train, X_test, y_test)\n"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.5403166735508742\n",
            "Classifier: LinearDiscriminantAnalysis [sample size: 2691]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time for training: 0.0244 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0016 sec\n",
            "F1 score: 0.4742 \n",
            "accuracy: 0.5452\n",
            "[on test set]\n",
            "time for prediction: 0.0013 sec\n",
            "F1 score: 0.4662 \n",
            "accuracy: 0.5425\n",
            "average F1: 0.4702\n",
            "\n",
            "\n",
            "After optimization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5403166735508742\n",
            "Classifier: LinearDiscriminantAnalysis [sample size: 2691]\n",
            "time for training: 0.0182 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0014 sec\n",
            "F1 score: 0.4742 \n",
            "accuracy: 0.5452\n",
            "[on test set]\n",
            "time for prediction: 0.0013 sec\n",
            "F1 score: 0.4662 \n",
            "accuracy: 0.5425\n",
            "average F1: 0.4702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jwNxO8j3g-O",
        "colab_type": "code",
        "outputId": "861e59ba-5029-408c-8139-87ae6cfc1cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#QDA()\n",
        "print('Before optimization')\n",
        "clf2 = QDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'reg_param': [0, 0.1, 0.01, 0.001],\n",
        "              'tol': [0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = QDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "qda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(qda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(qda_2, X_train, y_train, X_test, y_test)\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.4106237092110698\n",
            "Classifier: QuadraticDiscriminantAnalysis [sample size: 2691]\n",
            "time for training: 0.0061 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0036 sec\n",
            "F1 score: 0.4424 \n",
            "accuracy: 0.4400\n",
            "[on test set]\n",
            "time for prediction: 0.0019 sec\n",
            "F1 score: 0.4412 \n",
            "accuracy: 0.4359\n",
            "average F1: 0.4418\n",
            "\n",
            "\n",
            "After optimization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5068773234200743\n",
            "Classifier: QuadraticDiscriminantAnalysis [sample size: 2691]\n",
            "time for training: 0.0064 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0038 sec\n",
            "F1 score: 0.5199 \n",
            "accuracy: 0.5589\n",
            "[on test set]\n",
            "time for prediction: 0.0021 sec\n",
            "F1 score: 0.4836 \n",
            "accuracy: 0.5269\n",
            "average F1: 0.5017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uEQloCe4jOr",
        "colab_type": "code",
        "outputId": "808a5bc6-f06e-4576-8f6c-265ebac8708a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#Decision Tree\n",
        "print('Before optimization')\n",
        "clf2 = DecisionTreeClassifier()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "                'min_impurity_decrease':[0, 0.1, 1]\n",
        "             }\n",
        "clf = DecisionTreeClassifier()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "dtc_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(dtc_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(dtc_2, X_train, y_train, X_test, y_test)\n"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.4136018174308137\n",
            "Classifier: DecisionTreeClassifier [sample size: 2691]\n",
            "time for training: 0.0209 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0013 sec\n",
            "F1 score: 1.0000 \n",
            "accuracy: 1.0000\n",
            "[on test set]\n",
            "time for prediction: 0.0008 sec\n",
            "F1 score: 0.4342 \n",
            "accuracy: 0.4341\n",
            "average F1: 0.7171\n",
            "\n",
            "\n",
            "After optimization\n",
            "0.40950433705080547\n",
            "Classifier: DecisionTreeClassifier [sample size: 2691]\n",
            "time for training: 0.0210 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0012 sec\n",
            "F1 score: 1.0000 \n",
            "accuracy: 1.0000\n",
            "[on test set]\n",
            "time for prediction: 0.0009 sec\n",
            "F1 score: 0.4325 \n",
            "accuracy: 0.4324\n",
            "average F1: 0.7162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehaLX_Wc-_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MLP Classifier cannot be directly used as a base estimator in Ada Boosting estimator(sample_weight not available)\n",
        "#so this custom classifier will fix this problem\n",
        "#This can be found at: https://stackoverflow.com/questions/55632010/using-scikit-learns-mlpclassifier-in-adaboostclassifier\n",
        "class customMLPClassifier(MLPClassifier):\n",
        "    def resample_with_replacement(self, X_train, y_train, sample_weight):\n",
        "\n",
        "        # normalize sample_weights if not already\n",
        "        sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
        "\n",
        "        X_train_resampled = np.zeros((len(X_train), len(X_train[0])), dtype=np.float32)\n",
        "        y_train_resampled = np.zeros((len(y_train)), dtype=np.int)\n",
        "        for i in range(len(X_train)):\n",
        "            # draw a number from 0 to len(X_train)-1\n",
        "            draw = np.random.choice(np.arange(len(X_train)), p=sample_weight)\n",
        "\n",
        "            # place the X and y at the drawn number into the resampled X and y\n",
        "            X_train_resampled[i] = X_train[draw]\n",
        "            y_train_resampled[i] = y_train[draw]\n",
        "\n",
        "        return X_train_resampled, y_train_resampled\n",
        "\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        if sample_weight is not None:\n",
        "            X, y = self.resample_with_replacement(X, y, sample_weight)\n",
        "\n",
        "        return self._fit(X, y, incremental=(self.warm_start and\n",
        "                                            hasattr(self, \"classes_\")))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdajc1Hu6q8K",
        "colab_type": "code",
        "outputId": "413c6646-eb67-4997-b619-065fc13a467e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#Neural Network\n",
        "\n",
        "print('Before optimization')\n",
        "clf2 = customMLPClassifer()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'alpha': [ 1e-03, 1e-05, 1e-07],\n",
        "              'hidden_layer_sizes':[ (5,), (10,), (15,)],\n",
        "              'learning_rate_init':[0.01, 0.001, 0.0001],\n",
        "             }\n",
        "clf = customMLPClassifer()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "nn_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(nn_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(nn_2, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before optimization\n",
            "0.49386617100371744\n",
            "Classifier: customMLPClassifer [sample size: 2691]\n",
            "time for training: 3.3248 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0057 sec\n",
            "F1 score: 0.6389 \n",
            "accuracy: 0.6563\n",
            "[on test set]\n",
            "time for prediction: 0.0031 sec\n",
            "F1 score: 0.4909 \n",
            "accuracy: 0.5182\n",
            "average F1: 0.5649\n",
            "\n",
            "\n",
            "After optimization\n",
            "0.5072476937904447\n",
            "Classifier: customMLPClassifer [sample size: 2691]\n",
            "time for training: 0.4342 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0023 sec\n",
            "F1 score: 0.5148 \n",
            "accuracy: 0.5604\n",
            "[on test set]\n",
            "time for prediction: 0.0017 sec\n",
            "F1 score: 0.4868 \n",
            "accuracy: 0.5312\n",
            "average F1: 0.5008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWa8ykF6EXgC",
        "colab_type": "code",
        "outputId": "f293eceb-c4c8-4ef7-c067-09e5cf7c4531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#accuracy result after optimization\n",
        "#compare with previous result\n",
        "print(\"{:<32}{:20}{:20}\".format(\"classifier\", \"before\",\"after\" ))\n",
        "estimators = [lr_2, gaussian_2, lda_2, qda_2, dtc_2, nn_2]\n",
        "for i in range(0,len(estimators)):\n",
        "  estimators[i].fit(X_train, y_train)\n",
        "  y = estimators[i].predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y)\n",
        "  print(\"{:<32}{:<20}{:<20}\".format(estimators[i].__class__.__name__+':', result[i], accuracy ))\n",
        "\n",
        "#we can see that most classifier has slightly better performance after hyperparameter optimization"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier                      before              after               \n",
            "LogisticRegression:             0.511265164644714   0.5407279029462738  \n",
            "GaussianNB:                     0.5407279029462738  0.511265164644714   \n",
            "LinearDiscriminantAnalysis:     0.5424610051993067  0.5424610051993067  \n",
            "QuadraticDiscriminantAnalysis:  0.4358752166377816  0.5268630849220104  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier:         0.4150779896013865  0.4306759098786828  \n",
            "customMLPClassifer:             0.5268630849220104  0.5294627383015598  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpZTT6dZ4bo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "6ef80e48-d0a0-4a94-fc00-5dc38a880333"
      },
      "source": [
        "#Ensemble model use Ada boosting method\n",
        "#LDA and QDA cannot be used as base_estimator of ada boosting in scikit-learn, so we cannot ensemble these 2 estimators\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model1 = [lr_2, gaussian_2, dtc_2]\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)\n",
        "for estimator in model1:\n",
        "  model_ada = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = estimator)\n",
        "  results_ada = model_selection.cross_val_score(model_ada,X_train, y_train, cv=kfold_ada)\n",
        "  print(results_ada.mean())\n",
        "  train_predict(model_ada, X_train, y_train, X_test, y_test)\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "# clf = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = nn_2)\n",
        "# results_ada = model_selection.cross_val_score(clf,X_train, y_train, cv=kfold_ada)\n",
        "\n",
        "\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5373413190141816\n",
            "Classifier: AdaBoostClassifier [sample size: 2691]\n",
            "time for training: 0.3795 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0268 sec\n",
            "F1 score: 0.4690 \n",
            "accuracy: 0.5440\n",
            "[on test set]\n",
            "time for prediction: 0.0140 sec\n",
            "F1 score: 0.4604 \n",
            "accuracy: 0.5407\n",
            "average F1: 0.4647\n",
            "\n",
            "\n",
            "0.3344348065537656\n",
            "Classifier: AdaBoostClassifier [sample size: 2691]\n",
            "time for training: 0.1318 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0547 sec\n",
            "F1 score: 0.3324 \n",
            "accuracy: 0.3330\n",
            "[on test set]\n",
            "time for prediction: 0.0277 sec\n",
            "F1 score: 0.3258 \n",
            "accuracy: 0.3276\n",
            "average F1: 0.3291\n",
            "\n",
            "\n",
            "0.40393638992152\n",
            "Classifier: AdaBoostClassifier [sample size: 2691]\n",
            "time for training: 0.0230 sec\n",
            "[on train set]\n",
            "time for prediction: 0.0019 sec\n",
            "F1 score: 1.0000 \n",
            "accuracy: 1.0000\n",
            "[on test set]\n",
            "time for prediction: 0.0012 sec\n",
            "F1 score: 0.4160 \n",
            "accuracy: 0.4159\n",
            "average F1: 0.7080\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymJSfT6yojFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#final model, this gives better cross_validation_score and f1_score for test set\n",
        "final_model = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = lr_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RicM6wtp1jlf"
      },
      "source": [
        "# 5. Model Training & Validation [*Yanke*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h1cNAnlv1mVn"
      },
      "source": [
        "# 6. Result [*Yi*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ev2RFUeQ1pT2"
      },
      "source": [
        "# 7. Final Predictions on Test Set [*Yusi*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUC5szgpNFzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}