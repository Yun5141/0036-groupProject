{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FootballResultPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "outputs": [],
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yun5141/comp0036/blob/master/FootballResultPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RbwPTMh0lmA6"
      },
      "outputs": [],
      "source": [
        "# 1. Introduction [*Terry*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lNNXxH5mSMN"
      },
      "outputs": [],
      "source": [
        "# 2. Data Import  [*Yun*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------- import packages -----------------------\n",
        "import pandas as pd \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "#!pip3 install geopy\n",
        "from geopy.distance import geodesic \n",
        "from geopy.distance import great_circle \n",
        "\n",
        "#!pip3 install sklearn\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --------------------- import data -------------------------\n",
        "# training data set\n",
        "url=\"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-training.csv\"\n",
        "raw_training_data=pd.read_csv(url)\n",
        "\n",
        "# test set\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl-test.csv'\n",
        "rawData_toPred = pd.read_csv(url)\n",
        "\n",
        "# 2019 up-to-date data (from http://www.football-data.co.uk)\n",
        "url = 'https://raw.githubusercontent.com/Yun5141/comp0036/master/data/epl2019.csv'\n",
        "rawData_2019_uptodate = pd.read_csv(url)\n",
        "\n",
        "# geometric information of teams\n",
        "# to calculate the distance needed to travel for the away team\n",
        "url = \"https://raw.githubusercontent.com/Yun5141/comp0036/master/data/stadiums-with-GPS-coordinates.csv\"\n",
        "geometricData = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tnNgP1TpsS-c"
      },
      "outputs": [],
      "source": [
        "# 3. Data Transformation & Exploration [*Yun*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 3.1 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop unnamed columns\n",
        "raw_training_data = raw_training_data[raw_training_data.columns[~raw_training_data.columns.str.contains('Unnamed:')]]\n",
        "\n",
        "\n",
        "def removeInvalidData(data):\n",
        "\n",
        "    # remove data which contains None\n",
        "    data.dropna(axis=0, how='any',inplace=True)\n",
        "\n",
        "    # remove data which contains NaN, infinite or overflowed number \n",
        "    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    data = data[indices_to_keep]\n",
        "\n",
        "    return data\n",
        "\n",
        "#check if there are rows containing None, NaN, infinite or overflowed values\n",
        "assert raw_training_data.shape[0] == removeInvalidData(raw_training_data).shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# unify the different date formats and convert the type from str to timestamp  \n",
        "def unifyDate(data):\n",
        "    if not isinstance(data.Date[0],str):\n",
        "        return\n",
        "\n",
        "    newDate = []\n",
        "    for _, matchInfo in data.iterrows():\n",
        "        if len(matchInfo.Date) == 8 :\n",
        "            newDate.append(pd.to_datetime(matchInfo.Date, format=\"%d/%m/%y\" ))\n",
        "        elif len(matchInfo.Date) == 9 :\n",
        "            newDate.append(pd.to_datetime(matchInfo.Date, format=\"%d %b %y\" ))  # the date format in test data\n",
        "        elif len(matchInfo.Date) == 10 :\n",
        "            newDate.append(pd.to_datetime(matchInfo.Date, format=\"%d/%m/%Y\" ))\n",
        "    \n",
        "    data['Date'] = pd.Series(newDate).values\n",
        "\n",
        "    return data\n",
        "\n",
        "# unified the date formats for later exploration and transformation\n",
        "unifyDate(raw_training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7B_FaFS_38OD"
      },
      "outputs": [],
      "source": [
        "### 3.2 Initial Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GnAXcCh5NFyN"
      },
      "outputs": [],
      "source": [
        "##### 3.2.1 Number of matches per season"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# to see the number of matches each year (season)\n",
        "def separateData(data):\n",
        "    dataframe_collection = {}\n",
        "\n",
        "    for year in range(2008, 2019):\n",
        "        dataframe_collection[year] = data[(data.Date > dt.datetime(year,8,1,0,0) ) & (data.Date < dt.datetime(year+1, 6, 1,0,0))]\n",
        "\n",
        "    return dataframe_collection\n",
        "\n",
        "collection = separateData(raw_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "for key in collection.keys():\n",
        "    print(\"{} [{} rows x {} columns]\".format(key,collection[key].shape[0],collection[key].shape[1]))\n",
        "\n",
        "# The result shows that the number of matches each season stays the same (380)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zte3G2-BNFyT"
      },
      "outputs": [],
      "source": [
        "##### 3.2.2 Percentage of match result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def getPercentageOfMatchResult(data, matchResult):\n",
        "\n",
        "    if matchResult not in ['H', 'A', 'D']:\n",
        "        raise Exception('The second argument should only take values within [“H”,“A”,“D”]')\n",
        "    \n",
        "    n_wins = len(data[data.FTR == matchResult])\n",
        "\n",
        "    return n_wins / data.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# the average percentage of each match result per season\n",
        "for key in collection.keys():\n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [{}]\".format(key,len(collection[key])))\n",
        "    print(\"-\"*40)\n",
        "    print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"H\")*100))\n",
        "    print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"A\")*100))\n",
        "    print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(collection[key],\"D\")*100))\n",
        "\n",
        "# the average percentage over the 11 years\n",
        "print(\"\\n\" +\"=\"*40)\n",
        "print(\"Overall [{}]\".format(len(raw_training_data)))\n",
        "print(\"-\"*40)\n",
        "print(\"home team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"H\")*100))\n",
        "print(\"away team wins: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"A\")*100))\n",
        "print(\"draw: {:.3f}%\".format(getPercentageOfMatchResult(raw_training_data,\"D\")*100))\n",
        "\n",
        "# From the result, we find that in all cases the result 'home team wins' is of the highest probability, and 'H':'A':'D' $\\approx$ 5:3:2 in general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gRlWYgxKNFyb"
      },
      "outputs": [],
      "source": [
        "##### 3.2.3 Relationship between attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot Pearson Correlation Heatmap to see the top 10 features related to the match result FTR\n",
        "def plotGraph(X_all, Y_all):\n",
        "\n",
        "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
        "\n",
        "    #FTR correlation matrix\n",
        "    plt.figure(figsize=(12,12))\n",
        "    k = 11 # number of variables for heatmap\n",
        "    cols = abs(train_data.astype(float).corr()).nlargest(k, 'FTR')['FTR'].index\n",
        "    cm = np.corrcoef(train_data[cols].values.T)\n",
        "    sns.set(font_scale=1.25)\n",
        "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 12}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "    plt.show()\n",
        "\n",
        "attributes = raw_training_data.drop(['Date','HomeTeam', 'AwayTeam', 'Referee','FTR'],1)\n",
        "attributes['HTR'] = attributes['HTR'].map({'H':1,'A':0,'D':2})\n",
        "label = raw_training_data['FTR']\n",
        "label = label.map({'H':1,'A':0,'D':2})\n",
        "plotGraph(attributes,label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4bC5O7w4J16"
      },
      "outputs": [],
      "source": [
        "### 3.2 Feature Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# As within the top 10 features \n",
        "# there are two pairs of data highly correlated (see details in report), \n",
        "# so we just pick [FTHG, FTAG, HS, AS, HR, AR] from the top 10 features,\n",
        "# additional with [Date, HomeTeam, AwayTeam, FTR], to derive our features.\n",
        "selectedAttributes = [\"Date\",\"HomeTeam\", \"AwayTeam\",\"FTR\",\"FTHG\",\"FTAG\",\"HS\",\"AS\",\"HR\",\"AR\"]\n",
        "training_data = raw_training_data[selectedAttributes]\n",
        "\n",
        "# -------- Cumulative full time goal difference [HCGD, ACGD]-------------\n",
        "def getCumulativeGoalsDiff(data):\n",
        "    teams = {}\n",
        "    HCGD = [] \n",
        "    ACGD = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        # as the result in 3.2.1 shows that the number of matchese per season is always the same, so here we simply use i%380==0 to check if it is a new season and to initialize the feature.\n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []\n",
        "\n",
        "        FTHG = data.iloc[i]['FTHG']\n",
        "        FTAG = data.iloc[i]['FTAG']\n",
        "\n",
        "        try:\n",
        "            cgd_h = teams[data.iloc[i].HomeTeam].pop()\n",
        "            cgd_a = teams[data.iloc[i].AwayTeam].pop()\n",
        "        except:\n",
        "            cgd_h = 0\n",
        "            cgd_a = 0\n",
        "\n",
        "        HCGD.append(cgd_h)\n",
        "        ACGD.append(cgd_a)\n",
        "        cgd_h = cgd_h + FTHG - FTAG\n",
        "        teams[data.iloc[i].HomeTeam].append(cgd_h)\n",
        "        cgd_a = cgd_a + FTAG - FTHG\n",
        "        teams[data.iloc[i].AwayTeam].append(cgd_a)\n",
        "\n",
        "    data.loc[:,'HCGD'] = pd.Series(HCGD)\n",
        "    data.loc[:,'ACGD'] = pd.Series(ACGD)\n",
        "\n",
        "    return data\n",
        "\n",
        "# --------- Average number of shots on goal in the past 3 matches [HAHS, AAHS] ----------\n",
        "def getAverageShotsOnGoalInPast3Matches(data):\n",
        "    teams = {}\n",
        "    HAHS = [] \n",
        "    AAHS = []   \n",
        "\n",
        "    # for each match\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None]) #[3rd, 2nd, latest data]\n",
        "\n",
        "        try:\n",
        "            ahs_h = np.mean(teams[data.iloc[i].HomeTeam])\n",
        "            ahs_a = np.mean(teams[data.iloc[i].AwayTeam])\n",
        "        except:\n",
        "            ahs_h = None\n",
        "            ahs_a = None\n",
        "\n",
        "        HAHS.append(ahs_h)\n",
        "        AAHS.append(ahs_a)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].popleft()\n",
        "        teams[data.iloc[i].HomeTeam].append(data.iloc[i].HS)\n",
        "\n",
        "        teams[data.iloc[i].AwayTeam].popleft()\n",
        "        teams[data.iloc[i].AwayTeam].append(data.iloc[i].AS)\n",
        "\n",
        "    data.loc[:,'HAHS'] = pd.Series(HAHS)\n",
        "    data.loc[:,'AAHS'] = pd.Series(AAHS)\n",
        "\n",
        "    return data\n",
        "\n",
        "# ----------- Delta time from last match [HDT, ADT] ---------\n",
        "def getDeltaTime(data):\n",
        "    \n",
        "    teams = {}\n",
        "\n",
        "    HDT = []\n",
        "    ADT = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = []    # to store last match date\n",
        "\n",
        "        currentDate = data.iloc[i].Date\n",
        "\n",
        "        try:\n",
        "            homeLastMatchDate = teams[data.iloc[i].HomeTeam].pop()\n",
        "            awayLastMatchDate = teams[data.iloc[i].AwayTeam].pop()\n",
        "\n",
        "            hdt = (currentDate - homeLastMatchDate).days\n",
        "            adt = (currentDate - awayLastMatchDate).days\n",
        "        except:\n",
        "            homeLastMatchDate = currentDate\n",
        "            awayLastMatchDate = currentDate\n",
        "\n",
        "            hdt = None\n",
        "            adt = None\n",
        "\n",
        "        HDT.append(hdt)\n",
        "        ADT.append(adt)\n",
        "\n",
        "        teams[data.iloc[i].HomeTeam].append(currentDate)\n",
        "        teams[data.iloc[i].AwayTeam].append(currentDate)\n",
        "\n",
        "    data.loc[:,'HDT'] = HDT\n",
        "    data.loc[:,'ADT'] = ADT\n",
        "\n",
        "    return data\n",
        "\n",
        "# -------------- Distance needed to travel for the away team [DIS] ----------\n",
        "#The geometricData contains the latitude and longitude of teams\n",
        "def getDistance(data, geometricData):\n",
        "  array = []\n",
        "  for x in data.iterrows():\n",
        "   \n",
        "    home_lat = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Latitude\n",
        "    home_long = (geometricData.loc[geometricData['Team'] == x[1].HomeTeam]).Longitude\n",
        "    home_location = (np.float32(home_lat), np.float32(home_long))\n",
        "    \n",
        "    away_lat = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Latitude\n",
        "   \n",
        "    away_long = (geometricData.loc[geometricData['Team'] == x[1].AwayTeam]).Longitude\n",
        "    away_location = (np.float32(away_lat), np.float32(away_long))\n",
        "    array.append(np.float32(geodesic(home_location, away_location).km))\n",
        "  \n",
        "  \n",
        "  DIS = pd.Series(array)\n",
        "  data.loc[:,'DIS'] = DIS\n",
        "\n",
        "  return data\n",
        "\n",
        "# -------- Performances of last 3 matches [HM1, AM1, HM2, AM2, HM3, AM3] -------\n",
        "def getPerformanceOfLast3Matches(data):\n",
        "    HM1 = []    # result of the last match of home team\n",
        "    AM1 = []    # result of the last match of away team\n",
        "\n",
        "    HM2 = []    # result of the 2nd last match of home team\n",
        "    AM2 = []\n",
        "\n",
        "    HM3 = []    # result of the 3rd last match of home team\n",
        "    AM3 = []\n",
        "\n",
        "    teams = {}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        \n",
        "        if (i % 380 == 0):\n",
        "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
        "                teams[name] = deque([None, None, None])  #[3rd, 2nd, latest data]\n",
        "\n",
        "        HM3.append(teams[data.iloc[i].HomeTeam].popleft())\n",
        "        AM3.append(teams[data.iloc[i].AwayTeam].popleft())\n",
        "        HM2.append(teams[data.iloc[i].HomeTeam][0])\n",
        "        AM2.append(teams[data.iloc[i].AwayTeam][0])\n",
        "        HM1.append(teams[data.iloc[i].HomeTeam][1])\n",
        "        AM1.append(teams[data.iloc[i].AwayTeam][1])\n",
        "\n",
        "        if data.iloc[i].FTR == 'H':\n",
        "            # 主场 赢，则主场记为赢，客场记为输\n",
        "            teams[data.iloc[i].HomeTeam].append('W')\n",
        "            teams[data.iloc[i].AwayTeam].append('L')\n",
        "        elif data.iloc[i].FTR == 'A':\n",
        "            # 客场 赢，则主场记为输，客场记为赢\n",
        "            teams[data.iloc[i].AwayTeam].append('W')\n",
        "            teams[data.iloc[i].HomeTeam].append('L')\n",
        "        else:\n",
        "            # 平局\n",
        "            teams[data.iloc[i].AwayTeam].append('D')\n",
        "            teams[data.iloc[i].HomeTeam].append('D')\n",
        "\n",
        "    data.loc[:,'HM1'] = HM1\n",
        "    data.loc[:,'AM1'] = AM1\n",
        "    data.loc[:,'HM2'] = HM2\n",
        "    data.loc[:,'AM2'] = AM2\n",
        "    data.loc[:,'HM3'] = HM3\n",
        "    data.loc[:,'AM3'] = AM3\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TdUKOAbQNFy2"
      },
      "outputs": [],
      "source": [
        "##### 3.2.6 Derive features and remove invalid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# construct features\n",
        "getCumulativeGoalsDiff(training_data)   # FTHG, FTAG -> HCGD, ACGD\n",
        "getAverageShotsOnGoalInPast3Matches(training_data)  # HS, AS -> HAHS, AAHS\n",
        "getDeltaTime(training_data)     # Date -> HDT, ADT\n",
        "getDistance(training_data,geometricData)    # HomeTeam, AwayTeam -> DIS\n",
        "getPerformanceOfLast3Matches(training_data) # FTR -> HM1,AM1, HM2,AM2, HM3,AM3 [latest,2nd,3rd]\n",
        "\n",
        "# remove invalid data\n",
        "# Due to the lack of data in the beginning of each year, now there are rows containing empty values. \n",
        "training_data = removeInvalidData(training_data)\n",
        "\n",
        "# remove intermediate data\n",
        "dropedAttributes = selectedAttributes.copy()\n",
        "dropedAttributes.remove(\"HR\")\n",
        "dropedAttributes.remove(\"AR\")\n",
        "data = training_data.drop(dropedAttributes,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFBcPsCw41qB"
      },
      "outputs": [],
      "source": [
        "### 3.3 Second Data Exploration – Analyse Numerical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "numList = ['HR', 'AR', 'HCGD', 'ACGD', 'HAHS', 'AAHS', 'HDT', 'ADT', 'DIS']\n",
        "\n",
        "for col in numList:\n",
        "    l = data[col].tolist() \n",
        "    print(\"\\n\" +\"=\"*40)\n",
        "    print(\"{} [size: {}]\".format(col,len(l)))\n",
        "    print(\"-\"*40)\n",
        "    print(\"min: {:.4f} \\nmax: {:.4f} \\nmedian:{:.4f}\".format(np.min(l),np.max(l),np.median(l)))\n",
        "    print(\"mean: {:.4f} \\nvariance: {:.4f} \\nstandard deviation: {:.4f}\".format(np.mean(l),np.var(l), np.std(l, ddof=1)))\n",
        "\n",
        "# conclusions drawn from the result is included in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EkthKF7J4eiU"
      },
      "outputs": [],
      "source": [
        "### 3.4 Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate the training set into feature set and label:\n",
        "X_all = data.copy()\n",
        "y_all = training_data['FTR']\n",
        "\n",
        "# map string label into number\n",
        "rule = {'H':1, 'A':0, 'D':2}\n",
        "y_all = y_all.map(rule)\n",
        "\n",
        "# rescale and standardize numerical features\n",
        "# z-score standardization\n",
        "stdScaler = StandardScaler().fit(X_all[numList])\n",
        "X_all[numList] = stdScaler.transform(X_all[numList])\n",
        "\n",
        "# min-max scaling\n",
        "minmaxScaler = preprocessing.MinMaxScaler().fit(X_all[numList])\n",
        "X_all[numList] = minmaxScaler.transform(X_all[numList])\n",
        "\n",
        "# transform categorical features\n",
        "def transformCategoricalFeature(data,categoricalFeatureNames):\n",
        "    # transform feature to string\n",
        "    for col in categoricalFeatureNames:\n",
        "        data[col] = data[col].astype('str')\n",
        "    \n",
        "    output = pd.DataFrame(index=data.index)\n",
        "\n",
        "    for col_name, col_data in data.iteritems():\n",
        "        if col_data.dtype == 'object':\n",
        "            col_data = pd.get_dummies(col_data, prefix = col_name)\n",
        "        output = output.join(col_data)\n",
        "    \n",
        "    return output\n",
        "categList = [\"HM1\",\"AM1\", \"HM2\",\"AM2\", \"HM3\",\"AM3\"]\n",
        "X_all = transformCategoricalFeature(X_all, categList)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQchbTR5y393"
      },
      "outputs": [],
      "source": [
        "# 4. Methodology Overview [*Yanke*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Split data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,test_size = 0.3,random_state = 2,stratify = y_all)\n",
        "print(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove warning to see clear result\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Naive Bayes\n",
        "gaussian =GaussianNB()\n",
        "gaussian.fit(X_train, y_train)\n",
        "y_gaussian = gaussian.predict(X_test)\n",
        "accuracy1 = accuracy_score(y_test, y_gaussian)\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "lr = LogisticRegression(solver='lbfgs', multi_class = 'multinomial') # Must specify solver and multi_class to reduce warning\n",
        "lr.fit(X_train, y_train)\n",
        "y_lr = lr.predict(X_test)\n",
        "accuracy2 = accuracy_score(y_test, y_lr)\n",
        "\n",
        "\n",
        "#Linear Discriminant Analysis\n",
        "lda =LDA()\n",
        "lda.fit(X_train, y_train)\n",
        "y_lda = lda.predict(X_test)\n",
        "accuracy3 = accuracy_score(y_test, y_lda)\n",
        "\n",
        "#Quadratic Discriminant Analysis\n",
        "qda =QDA()\n",
        "qda.fit(X_train, y_train)\n",
        "y_qda = qda.predict(X_test)\n",
        "accuracy4 = accuracy_score(y_test, y_qda)\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "dtc =DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "y_dtc = dtc.predict(X_test)\n",
        "accuracy5 = accuracy_score(y_test, y_dtc)\n",
        "\n",
        "\n",
        "#Multilayer Perceptron, a feedforward artificial Neural Net work model\n",
        "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(15,), random_state=1)\n",
        "nn.fit(X_train, y_train)\n",
        "y_nn = nn.predict(X_test)\n",
        "accuracy6 = accuracy_score(y_test, y_nn)\n",
        "\n",
        "print(\"{:<38}{}\".format('Gaussian Naive Bayes:',accuracy1))\n",
        "print(\"{:<38}{}\".format('Logistic Regression:',accuracy2))\n",
        "print(\"{:<38}{}\".format('Linear Discriminant Analysis:',accuracy3))\n",
        "print(\"{:<38}{}\".format('Quadratic Discriminant Analysis:',accuracy4))\n",
        "print(\"{:<38}{}\".format('Decision Tree:',accuracy5))\n",
        "print(\"{:<38}{}\".format('Multilayer Perceptron(Neural Network):',accuracy6))\n",
        "result=[accuracy1,accuracy2, accuracy3, accuracy4, accuracy5,accuracy6]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import time\n",
        "from sklearn.metrics import f1_score\n",
        "# train classifier\n",
        "def train_classifier(clf, X_train, y_train):\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    print(\"time for training: {:.4f} sec\".format(end - start))\n",
        "\n",
        "# predict using the classifier\n",
        "def predict_labels(clf, features, target):\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    end = time()\n",
        "    print(\"time for prediction: {:.4f} sec\".format(end - start))\n",
        "    return f1_score(target, y_pred, pos_label=1, average=\"weighted\"), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "# print out the performance of each classifer\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    print(\"Classifier: {} [sample size: {}]\".format(clf.__class__.__name__, len(X_train)))\n",
        "\n",
        "    train_classifier(clf, X_train, y_train)\n",
        "\n",
        "    # evaluate model on train set\n",
        "    print(\"[on train set]\")\n",
        "    f1a, acc = predict_labels(clf, X_train, y_train)\n",
        "    print(\"F1 score: {:.4f} \".format(f1a))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "\n",
        "    # evaluate model on test set\n",
        "    print(\"[on test set]\")\n",
        "    f1b, acc = predict_labels(clf, X_test, y_test)\n",
        "    print(\"F1 score: {:.4f} \".format(f1b))\n",
        "    print(\"accuracy: {:.4f}\".format(acc))\n",
        "    print(\"average F1: {:.4f}\".format((f1a+f1b)/2))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "# adjust the hyperparameter of the model with best f1_score using grid search  \n",
        "def adjustClassifier(clf, f1_scorer, param, X_train, y_train):\n",
        "\n",
        "    grid_obj = GridSearchCV(clf,scoring=f1_scorer,param_grid=param,cv=5)\n",
        "    grid_obj = grid_obj.fit(X_train,y_train)\n",
        "\n",
        "    clf = grid_obj.best_estimator_\n",
        "\n",
        "    return clf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#cross-validation with KFold\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "#Logistic Regression\n",
        "#Score Before optimization\n",
        "print('Before optimization')\n",
        "clf2 = LogisticRegression(solver='lbfgs', multi_class = 'multinomial')\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Score after optimization\n",
        "print('After Optimization')\n",
        "clf = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial')\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')   #f1-scorer, need to set average to 'weighted' since target is multi class\n",
        "# set hyper parameter to be optimised\n",
        "parameters = { \n",
        "              'C' :[1.0, 100.0, 1000.0],\n",
        "              'max_iter':[100,200,300, 400, 500],\n",
        "              'intercept_scaling':[0.1, 0.5, 1.0]\n",
        "             }\n",
        "lr_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lr_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lr_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GaussianNB\n",
        "print('Before optimization')\n",
        "clf2 = GaussianNB()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "clf = GaussianNB()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "parameters = { \n",
        "              'var_smoothing': [1e-09, 1e-07, 1e-05, 1e-11, 1e-13]\n",
        "             }\n",
        "gaussian_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(gaussian_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(gaussian_2, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#LDA\n",
        "print('Before optimization')\n",
        "clf2 = LDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'tol': [ 0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = LDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper paramete\n",
        "lda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(lda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(lda_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#QDA()\n",
        "print('Before optimization')\n",
        "clf2 = QDA()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'reg_param': [0, 0.1, 0.01, 0.001],\n",
        "              'tol': [0.001, 0.0001, 0.00001]\n",
        "             }\n",
        "clf = QDA()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "qda_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(qda_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(qda_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "print('Before optimization')\n",
        "clf2 = DecisionTreeClassifier()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "                'min_impurity_decrease':[0, 0.1, 1]\n",
        "             }\n",
        "clf = DecisionTreeClassifier()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "dtc_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(dtc_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(dtc_2, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#MLP Classifier cannot be directly used as a base estimator in Ada Boosting estimator(sample_weight not available)\n",
        "#so this custom classifier will fix this problem\n",
        "#This can be found at: https://stackoverflow.com/questions/55632010/using-scikit-learns-mlpclassifier-in-adaboostclassifier\n",
        "class customMLPClassifier(MLPClassifier):\n",
        "    def resample_with_replacement(self, X_train, y_train, sample_weight):\n",
        "\n",
        "        # normalize sample_weights if not already\n",
        "        sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
        "\n",
        "        X_train_resampled = np.zeros((len(X_train), len(X_train[0])), dtype=np.float32)\n",
        "        y_train_resampled = np.zeros((len(y_train)), dtype=np.int)\n",
        "        for i in range(len(X_train)):\n",
        "            # draw a number from 0 to len(X_train)-1\n",
        "            draw = np.random.choice(np.arange(len(X_train)), p=sample_weight)\n",
        "\n",
        "            # place the X and y at the drawn number into the resampled X and y\n",
        "            X_train_resampled[i] = X_train[draw]\n",
        "            y_train_resampled[i] = y_train[draw]\n",
        "\n",
        "        return X_train_resampled, y_train_resampled\n",
        "\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        if sample_weight is not None:\n",
        "            X, y = self.resample_with_replacement(X, y, sample_weight)\n",
        "\n",
        "        return self._fit(X, y, incremental=(self.warm_start and\n",
        "                                            hasattr(self, \"classes_\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "\n",
        "print('Before optimization')\n",
        "clf2 = customMLPClassifer()\n",
        "results = model_selection.cross_val_score(clf2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(clf2, X_train, y_train, X_test, y_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print('After optimization')\n",
        "parameters = { \n",
        "              'alpha': [ 1e-03, 1e-05, 1e-07],\n",
        "              'hidden_layer_sizes':[ (5,), (10,), (15,)],\n",
        "              'learning_rate_init':[0.01, 0.001, 0.0001],\n",
        "             }\n",
        "clf = customMLPClassifer()\n",
        "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
        "# use grid search to optimise hyper parameter\n",
        "nn_2 = adjustClassifier(clf, f1_scorer, parameters, X_train, y_train)\n",
        "results = model_selection.cross_val_score(nn_2,X_train, y_train, cv=kfold_ada)\n",
        "print(results.mean())\n",
        "train_predict(nn_2, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#accuracy result after optimization\n",
        "#compare with previous result\n",
        "print(\"{:<32}{:20}{:20}\".format(\"classifier\", \"before\",\"after\" ))\n",
        "estimators = [lr_2, gaussian_2, lda_2, qda_2, dtc_2, nn_2]\n",
        "for i in range(0,len(estimators)):\n",
        "  estimators[i].fit(X_train, y_train)\n",
        "  y = estimators[i].predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y)\n",
        "  print(\"{:<32}{:<20}{:<20}\".format(estimators[i].__class__.__name__+':', result[i], accuracy ))\n",
        "\n",
        "#we can see that most classifier has slightly better performance after hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ensemble model use Ada boosting method\n",
        "#LDA and QDA cannot be used as base_estimator of ada boosting in scikit-learn, so we cannot ensemble these 2 estimators\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model1 = [lr_2, gaussian_2, dtc_2]\n",
        "kfold_ada = model_selection.KFold(n_splits=10, random_state=10)\n",
        "for estimator in model1:\n",
        "  model_ada = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = estimator)\n",
        "  results_ada = model_selection.cross_val_score(model_ada,X_train, y_train, cv=kfold_ada)\n",
        "  print(results_ada.mean())\n",
        "  train_predict(model_ada, X_train, y_train, X_test, y_test)\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "# clf = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = nn_2)\n",
        "# results_ada = model_selection.cross_val_score(clf,X_train, y_train, cv=kfold_ada)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "#final model, this gives better cross_validation_score and f1_score for test set\n",
        "final_model = AdaBoostClassifier(n_estimators=30, random_state=10, base_estimator = lr_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RicM6wtp1jlf"
      },
      "outputs": [],
      "source": [
        "# 5. Model Training & Validation [*Yanke*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h1cNAnlv1mVn"
      },
      "outputs": [],
      "source": [
        "# 6. Result [*Yi*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ev2RFUeQ1pT2"
      },
      "outputs": [],
      "source": [
        "# 7. Final Predictions on Test Set [*Yusi*]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XUC5szgpNFzU"
      },
      "outputs": [],
      "source": []
    }
  ]
}